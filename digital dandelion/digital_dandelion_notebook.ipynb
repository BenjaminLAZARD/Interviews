{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8df51c-537e-48c5-a735-af1c8951f590",
   "metadata": {},
   "source": [
    "# End-to-End Solution\n",
    "\n",
    "This notebook is built assuming a GPU environment is available.\n",
    "This is of course just a jupyter demo, but cuda should be enabled.\n",
    "\n",
    "If using a free  jupyter notebook environment, use a T4 GPU environment. You can even [open a terminal now](https://blog.infuseai.io/run-a-full-tty-terminal-in-google-colab-without-colab-pro-2759b9f8a74a)\n",
    "\n",
    "## Dependencies management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1513937d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T19:25:16.055127Z",
     "iopub.status.busy": "2024-03-01T19:25:16.054748Z",
     "iopub.status.idle": "2024-03-01T19:25:16.680375Z",
     "shell.execute_reply": "2024-03-01T19:25:16.679582Z",
     "shell.execute_reply.started": "2024-03-01T19:25:16.055098Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/bin/mamba\n"
     ]
    }
   ],
   "source": [
    "# pick a dependency solver.\n",
    "# here I use saturn cloud (Google Colab GPU ran out on me) and mamba is preinstalled\n",
    "# I usually pick mamba, poetry and uv\n",
    "! which mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "339906d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T19:29:27.898017Z",
     "iopub.status.busy": "2024-03-01T19:29:27.897626Z",
     "iopub.status.idle": "2024-03-01T19:30:53.065323Z",
     "shell.execute_reply": "2024-03-01T19:30:53.064552Z",
     "shell.execute_reply.started": "2024-03-01T19:29:27.897984Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for: ['tensorflow-gpu', 'ffmpeg', 'ffmpeg-python', 'srt', 'pytorch', 'torchvision', 'torchaudio', 'pytorch-cuda=12', 'pyaudio']\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "pytorch/linux-64 (check zst) \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpytorch/linux-64 (check zst)                        Checked  0.2s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpytorch/noarch (check zst)                         Checked  0.0s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/linux-64 (check zst)                        Checked  0.0s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "nvidia/noarch (check zst) \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/noarch (check zst)                           Checked  0.0s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64 (check zst)                     Checked  0.1s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/noarch (check zst)                       Checked  0.0s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "pkgs/r/linux-64 (check zst) \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/linux-64 (check zst)                         Checked  0.0s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/noarch (check zst)                          Checked  0.0s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpytorch/linux-64                                   191.6kB @   2.4MB/s  0.1s\n",
      "pytorch/noarch                                      10.9kB @ 117.0kB/s  0.1s\n",
      "[+] 0.1s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "nvidia/linux-64      \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "nvidia/noarch        \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/main/noarch     \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\n",
      "pkgs/r/noarch        \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/noarch                                        5.2kB @  51.4kB/s  0.1s\n",
      "nvidia/linux-64                                    161.3kB @   1.3MB/s  0.1s\n",
      "[+] 0.2s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 895.4kB /  32.8MB @   5.8MB/s  0.2s\n",
      "pkgs/main/linux-64   \u001b[90m━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/main/noarch     ━━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m 109.9kB / 703.9kB @ 556.2kB/s  0.1s\n",
      "pkgs/r/linux-64      \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/r/noarch        ━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m 261.1kB /   2.1MB @   1.4MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/noarch                                        2.1MB @   8.2MB/s  0.2s\n",
      "pkgs/main/noarch                                   703.9kB @   2.7MB/s  0.2s\n",
      "[+] 0.3s\n",
      "conda-forge/linux-64 ╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2.8MB /  32.8MB @  13.1MB/s  0.3s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\n",
      "pkgs/main/linux-64   ━━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━\u001b[0m   2.6MB /   5.9MB @   9.4MB/s  0.2s\n",
      "pkgs/r/linux-64      ━━━━━╸\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m 490.4kB /   1.6MB @   2.1MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/linux-64                                      1.6MB @   4.9MB/s  0.2s\n",
      "pkgs/main/linux-64                                   5.9MB @  16.2MB/s  0.3s\n",
      "[+] 0.4s\n",
      "conda-forge/linux-64 ━━━━━╸\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m   9.2MB /  32.8MB @  24.3MB/s  0.4s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━╸\u001b[90m━━━━━━━━━\u001b[0m  21.1MB /  32.8MB @  43.1MB/s  0.5s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━━\u001b[0m  27.5MB /  32.8MB @  46.1MB/s  0.6s\n",
      "conda-forge/noarch   ╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   1.0MB /  13.7MB @   1.8MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                  13.7MB @  20.3MB/s  0.4s\n",
      "[+] 0.7s\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━━\u001b[0m  27.5MB /  32.8MB @  42.3MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                                32.8MB @  41.7MB/s  0.8s\n",
      "\u001b[?25h\n",
      "Pinned packages:\n",
      "  - python 3.10.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/saturncloud/envs/saturn\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - tensorflow-gpu\n",
      "   - ffmpeg\n",
      "   - ffmpeg-python\n",
      "   - srt\n",
      "   - pytorch\n",
      "   - torchvision\n",
      "   - torchaudio\n",
      "   - pytorch-cuda=12\n",
      "   - pyaudio\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package                    Version  Build                    Channel          Size\n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[32m+ keras               \u001b[0m      2.15.0  pyhd8ed1ab_0             conda-forge     900kB\n",
      "  \u001b[32m+ python-flatbuffers  \u001b[0m     23.5.26  pyhd8ed1ab_0             conda-forge      34kB\n",
      "  \u001b[32m+ future              \u001b[0m       1.0.0  pyhd8ed1ab_0             conda-forge     364kB\n",
      "  \u001b[32m+ cuda-version        \u001b[0m        12.3  h32bc705_2               conda-forge      21kB\n",
      "  \u001b[32m+ opt_einsum          \u001b[0m       3.3.0  pyhc1e730c_2             conda-forge      58kB\n",
      "  \u001b[32m+ termcolor           \u001b[0m       2.4.0  pyhd8ed1ab_0             conda-forge      13kB\n",
      "  \u001b[32m+ astunparse          \u001b[0m       1.6.3  pyhd8ed1ab_0             conda-forge      16kB\n",
      "  \u001b[32m+ gast                \u001b[0m       0.5.4  pyhd8ed1ab_0             conda-forge      24kB\n",
      "  \u001b[32m+ google-pasta        \u001b[0m       0.2.0  pyh8c360ce_0             conda-forge      43kB\n",
      "  \u001b[32m+ cached_property     \u001b[0m       1.5.2  pyha770c72_1             conda-forge      11kB\n",
      "  \u001b[32m+ ffmpeg-python       \u001b[0m       0.2.0  py_0                     conda-forge      25kB\n",
      "  \u001b[32m+ cached-property     \u001b[0m       1.5.2  hd8ed1ab_1               conda-forge       4kB\n",
      "  \u001b[32m+ srt                 \u001b[0m       3.5.3  py310hff52083_0          conda-forge      30kB\n",
      "  \u001b[32m+ flatbuffers         \u001b[0m     23.5.26  h59595ed_1               conda-forge       2MB\n",
      "  \u001b[32m+ ml_dtypes           \u001b[0m       0.2.0  py310hcc13569_2          conda-forge     689kB\n",
      "  \u001b[32m+ portaudio           \u001b[0m      19.6.0  h7c63dc7_9               conda-forge     116kB\n",
      "  \u001b[32m+ libdb               \u001b[0m      6.2.32  h9c3ff4c_0               conda-forge      24MB\n",
      "  \u001b[32m+ nccl                \u001b[0m    2.20.3.1  h3a97aeb_0               conda-forge     109MB\n",
      "  \u001b[32m+ cudnn               \u001b[0m   8.8.0.121  h264754d_4               conda-forge     476MB\n",
      "  \u001b[32m+ cuda-nvvm-tools     \u001b[0m    12.3.107  h59595ed_0               conda-forge      12MB\n",
      "  \u001b[32m+ cuda-crt-tools      \u001b[0m    12.3.107  ha770c72_0               conda-forge      26kB\n",
      "  \u001b[32m+ h5py                \u001b[0m      3.10.0  nompi_py310h65828d5_101  conda-forge       1MB\n",
      "  \u001b[32m+ jack                \u001b[0m      1.9.22  h7c63dc7_2               conda-forge     464kB\n",
      "  \u001b[32m+ cuda-nvcc-tools     \u001b[0m    12.3.107  hd3aeb46_0               conda-forge      23MB\n",
      "  \u001b[32m+ pyaudio             \u001b[0m      0.2.14  py310h2372a71_0          conda-forge      35kB\n",
      "  \u001b[32m+ tensorflow-base     \u001b[0m      2.15.0  cuda120py310heceb7ac_3   conda-forge     338MB\n",
      "  \u001b[32m+ tensorflow-estimator\u001b[0m      2.15.0  cuda120py310h549c77d_3   conda-forge     550kB\n",
      "  \u001b[32m+ tensorflow          \u001b[0m      2.15.0  cuda120py310h9360858_3   conda-forge      40kB\n",
      "  \u001b[32m+ tensorflow-gpu      \u001b[0m      2.15.0  cuda120py310hb76ca00_3   conda-forge      39kB\n",
      "\n",
      "  Change:\n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[31m- ucx                 \u001b[0m      1.15.0  h75e419f_3               conda-forge      15MB\n",
      "  \u001b[32m+ ucx                 \u001b[0m      1.15.0  h6d2d1ec_3               conda-forge      15MB\n",
      "\n",
      "  Upgrade:\n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[31m- certifi             \u001b[0m  2023.11.17  pyhd8ed1ab_0             conda-forge     159kB\n",
      "  \u001b[32m+ certifi             \u001b[0m    2024.2.2  pyhd8ed1ab_0             conda-forge     161kB\n",
      "  \u001b[31m- ca-certificates     \u001b[0m  2023.11.17  hbcca054_0               conda-forge     154kB\n",
      "  \u001b[32m+ ca-certificates     \u001b[0m    2024.2.2  hbcca054_0               conda-forge     155kB\n",
      "  \u001b[31m- openssl             \u001b[0m       3.2.0  hd590300_1               conda-forge       3MB\n",
      "  \u001b[32m+ openssl             \u001b[0m       3.2.1  hd590300_0               conda-forge       3MB\n",
      "\n",
      "  Downgrade:\n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[31m- wrapt               \u001b[0m      1.16.0  py310h2372a71_0          conda-forge      55kB\n",
      "  \u001b[32m+ wrapt               \u001b[0m      1.14.1  py310h5764c6d_1          conda-forge      52kB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 29 packages\n",
      "  Change: 1 packages\n",
      "  Upgrade: 3 packages\n",
      "  Downgrade: 1 packages\n",
      "\n",
      "  Total download: 1GB\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "Downloading      \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B                            0.0s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "Downloading  (5) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B certifi                    0.0s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpython-flatbuffers                                  34.1kB @ 312.7kB/s  0.1s\n",
      "certifi                                            160.6kB @   1.1MB/s  0.1s\n",
      "cuda-version                                        21.1kB @ 128.2kB/s  0.2s\n",
      "cached_property                                     11.1kB @  67.1kB/s  0.1s\n",
      "[+] 0.2s\n",
      "Downloading  (5) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 803.0kB flatbuffers                0.1s\n",
      "Extracting   (4) \u001b[90m━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m       0 cached_property            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfuture                                             364.1kB @   1.7MB/s  0.2s\n",
      "wrapt                                               52.2kB @ 246.3kB/s  0.0s\n",
      "keras                                              900.0kB @   3.5MB/s  0.3s\n",
      "srt                                                 29.7kB @  99.9kB/s  0.2s\n",
      "[+] 0.3s\n",
      "Downloading  (5) \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m   1.8MB flatbuffers                0.2s\n",
      "Extracting   (3) ━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m       4 future                     0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gh5py                                                 1.2MB @   3.5MB/s  0.1s\n",
      "flatbuffers                                          1.6MB @   4.3MB/s  0.2s\n",
      "[+] 0.4s\n",
      "Downloading  (5) \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m  10.4MB cuda-nvcc-tools            0.3s\n",
      "Extracting   (3) ━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m       7 flatbuffers                0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gopt_einsum                                          58.0kB @ 141.8kB/s  0.1s\n",
      "tensorflow-estimator                               550.5kB @   1.2MB/s  0.2s\n",
      "gast                                                23.6kB @  52.0kB/s  0.1s\n",
      "cached-property                                      4.1kB @   9.1kB/s  0.0s\n",
      "[+] 0.5s\n",
      "Downloading  (5) \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m  23.8MB cuda-nvcc-tools            0.4s\n",
      "Extracting   (4) ━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m      10 cached-property            0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gml_dtypes                                          689.1kB @   1.3MB/s  0.1s\n",
      "portaudio                                          115.5kB @ 212.8kB/s  0.1s\n",
      "[+] 0.6s\n",
      "Downloading  (5) \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m  27.1MB cuda-nvcc-tools            0.5s\n",
      "Extracting   (2) ━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m      14 ml_dtypes                  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gjack                                               464.1kB @ 748.5kB/s  0.1s\n",
      "openssl                                              2.9MB @   4.4MB/s  0.1s\n",
      "[+] 0.7s\n",
      "Downloading  (5) \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m  40.2MB cuda-nvcc-tools            0.6s\n",
      "Extracting   (3) ━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m      15 ml_dtypes                  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gastunparse                                          15.5kB @  21.9kB/s  0.1s\n",
      "cuda-nvcc-tools                                     23.0MB @  29.4MB/s  0.5s\n",
      "[+] 0.8s\n",
      "Downloading  (5) ╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m  62.4MB cudnn                      0.7s\n",
      "Extracting   (2) ━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m      18 astunparse                 0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpyaudio                                             35.0kB @  43.5kB/s  0.1s\n",
      "tensorflow-gpu                                      39.4kB @  46.9kB/s  0.1s\n",
      "[+] 0.9s\n",
      "Downloading  (5) ╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m  78.1MB cudnn                      0.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m      20 cuda-nvcc-tools            0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gffmpeg-python                                       25.4kB @  27.6kB/s  0.1s\n",
      "ucx                                                 15.4MB @  15.7MB/s  0.3s\n",
      "cuda-crt-tools                                      26.1kB @  26.3kB/s  0.1s\n",
      "[+] 1.0s\n",
      "Downloading  (5) ━╸\u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m  97.9MB cudnn                      0.9s\n",
      "Extracting   (3) ━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m      21 cuda-nvcc-tools            0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibdb                                               24.4MB @  24.5MB/s  0.5s\n",
      "ca-certificates                                    155.4kB @ 151.1kB/s  0.0s\n",
      "cuda-nvvm-tools                                     11.6MB @  11.0MB/s  0.2s\n",
      "google-pasta                                        43.2kB @  40.9kB/s  0.1s\n",
      "[+] 1.1s\n",
      "Downloading  (5) ━╸\u001b[33m━━━━━━━━━━━━━━━━━━━━━\u001b[0m 110.0MB cudnn                      1.0s\n",
      "Extracting   (7) ━━━━━━━━━━━━━╸\u001b[33m━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m      22 cuda-nvcc-tools            0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gtermcolor                                           12.7kB @  11.2kB/s  0.1s\n",
      "tensorflow                                          39.8kB @  34.0kB/s  0.1s\n",
      "[+] 1.2s\n",
      "Downloading  (3) ━╸\u001b[33m━━━━━━━━━━━━━━━━━━━━━\u001b[0m 122.1MB nccl                       1.1s\n",
      "Extracting   (7) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━\u001b[0m      24 cuda-nvcc-tools            1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
      "Downloading  (3) ━╸\u001b[33m━━━━━━━━━━━━━━━━━━━━━\u001b[0m 133.8MB nccl                       1.2s\n",
      "Extracting   (5) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━\u001b[0m      26 cuda-nvvm-tools            1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
      "Downloading  (3) ━━╸\u001b[33m━━━━━━━━━━━━━━━━━━━━\u001b[0m 151.8MB nccl                       1.3s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━\u001b[0m      28 cuda-nvvm-tools            1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
      "Downloading  (3) ━━╸\u001b[33m━━━━━━━━━━━━━━━━━━━━\u001b[0m 168.2MB nccl                       1.4s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━\u001b[0m      29 cuda-nvvm-tools            1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
      "Downloading  (3) ━━━╸\u001b[33m━━━━━━━━━━━━━━━━━━━\u001b[0m 182.7MB tensorflow-base            1.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
      "Downloading  (3) ━━━╸\u001b[33m━━━━━━━━━━━━━━━━━━━\u001b[0m 192.8MB tensorflow-base            1.6s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
      "Downloading  (3) ━━━╸\u001b[33m━━━━━━━━━━━━━━━━━━━\u001b[0m 207.8MB tensorflow-base            1.7s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      1.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
      "Downloading  (3) ━━━━╸\u001b[33m━━━━━━━━━━━━━━━━━━\u001b[0m 224.5MB tensorflow-base            1.8s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
      "Downloading  (3) ━━━━╸\u001b[33m━━━━━━━━━━━━━━━━━━\u001b[0m 247.6MB cudnn                      1.9s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      1.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
      "Downloading  (3) ━━━━╸\u001b[33m━━━━━━━━━━━━━━━━━━\u001b[0m 261.9MB cudnn                      2.0s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      1.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
      "Downloading  (3) ━━━━━╸\u001b[33m━━━━━━━━━━━━━━━━━\u001b[0m 278.7MB cudnn                      2.1s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      2.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
      "Downloading  (3) ━━━━━╸\u001b[33m━━━━━━━━━━━━━━━━━\u001b[0m 283.2MB cudnn                      2.2s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      2.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
      "Downloading  (3) ━━━━━╸\u001b[33m━━━━━━━━━━━━━━━━━\u001b[0m 304.8MB nccl                       2.3s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      2.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
      "Downloading  (3) ━━━━━━╸\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m 322.5MB nccl                       2.4s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      2.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
      "Downloading  (3) ━━━━━━╸\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m 335.9MB nccl                       2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      2.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
      "Downloading  (3) ━━━━━━╸\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m 348.7MB nccl                       2.6s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      2.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
      "Downloading  (3) ━━━━━━━╸\u001b[33m━━━━━━━━━━━━━━━\u001b[0m 360.0MB tensorflow-base            2.7s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      2.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
      "Downloading  (3) ━━━━━━━╸\u001b[33m━━━━━━━━━━━━━━━\u001b[0m 393.5MB tensorflow-base            2.8s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      2.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
      "Downloading  (3) ━━━━━━━━╸\u001b[33m━━━━━━━━━━━━━━\u001b[0m 418.6MB tensorflow-base            2.9s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      2.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
      "Downloading  (3) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━━\u001b[0m 445.0MB tensorflow-base            3.0s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      2.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
      "Downloading  (3) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━━\u001b[0m 470.9MB cudnn                      3.1s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━\u001b[0m      30 libdb                      3.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnccl                                               109.0MB @  33.8MB/s  2.2s\n",
      "[+] 3.3s\n",
      "Downloading  (2) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m 494.0MB cudnn                      3.2s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 libdb                      3.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
      "Downloading  (2) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m 523.4MB cudnn                      3.3s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 libdb                      3.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
      "Downloading  (2) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━\u001b[0m 541.9MB cudnn                      3.4s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 libdb                      3.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
      "Downloading  (2) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━\u001b[0m 560.5MB tensorflow-base            3.5s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 nccl                       3.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
      "Downloading  (2) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m 574.4MB tensorflow-base            3.6s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 nccl                       3.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
      "Downloading  (2) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m 596.4MB tensorflow-base            3.7s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 nccl                       3.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
      "Downloading  (2) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m 610.0MB tensorflow-base            3.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 nccl                       3.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
      "Downloading  (2) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m 624.5MB cudnn                      3.9s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 libdb                      3.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
      "Downloading  (2) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m 644.4MB cudnn                      4.0s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 libdb                      3.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m 674.0MB cudnn                      4.1s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 libdb                      4.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m 692.7MB cudnn                      4.2s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 libdb                      4.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m 712.3MB tensorflow-base            4.3s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 nccl                       4.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m 738.4MB tensorflow-base            4.4s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 nccl                       4.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m 754.5MB tensorflow-base            4.5s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 nccl                       4.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m 777.7MB tensorflow-base            4.6s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      30 nccl                       4.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m 802.4MB cudnn                      4.7s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      31 libdb                      4.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m 824.5MB cudnn                      4.8s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      31 libdb                      4.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m 849.1MB cudnn                      4.9s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      31 libdb                      4.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m 870.8MB cudnn                      5.0s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      31 libdb                      4.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.2s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m 882.0MB tensorflow-base            5.1s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      31 libdb                      5.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m 907.6MB tensorflow-base            5.2s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      31 libdb                      5.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 933.1MB tensorflow-base            5.3s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      31 libdb                      5.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 946.8MB tensorflow-base            5.4s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m      31 libdb                      5.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gtensorflow-base                                    337.5MB @  60.4MB/s  4.6s\n",
      "[+] 5.6s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 969.3MB cudnn                      5.5s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m      31 tensorflow-base            5.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.7s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 981.0MB cudnn                      5.6s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m      31 tensorflow-base            5.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 995.0MB cudnn                      5.7s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m      31 tensorflow-base            5.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gcudnn                                              476.5MB @  81.7MB/s  5.6s\n",
      "[+] 5.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            5.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      5.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      5.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      6.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      6.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            6.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            6.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            6.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            6.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      6.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      6.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      6.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      6.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            7.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            7.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            7.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            7.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      7.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      7.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      7.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      7.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            7.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            7.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            8.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            8.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      8.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      8.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      8.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      8.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            8.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            8.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            8.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            8.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      9.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      9.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      9.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      9.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            9.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            9.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            9.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base            9.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      9.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                      9.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     10.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     10.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           10.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           10.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           10.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           10.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     10.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     10.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     10.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     10.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           11.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           11.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           11.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           11.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     11.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     11.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     11.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     11.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           11.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           11.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           12.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           12.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     12.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     12.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     12.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     12.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           12.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           12.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           12.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           12.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     13.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     13.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     13.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     13.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           13.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           13.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           13.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           13.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     13.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     13.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     14.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     14.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           14.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           14.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           14.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           14.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     14.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     14.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     14.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     14.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           15.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           15.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           15.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 tensorflow-base           15.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     15.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     15.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     15.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      32 cudnn                     15.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 16.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      33 cudnn                     15.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 16.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      33 cudnn                     15.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 16.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      33 cudnn                     16.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 16.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      33 cudnn                     16.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 16.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      33 cudnn                     16.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 16.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   1.0GB                            5.8s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━━━      34                           16.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: | By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\n",
      "  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "! mamba install -y tensorflow-gpu ffmpeg ffmpeg-python srt pytorch torchvision torchaudio pytorch-cuda==12.* pyaudio -c pytorch -c nvidia -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58dc7e5-54b9-4673-9f84-c1ca77eb895e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T19:31:04.634751Z",
     "iopub.status.busy": "2024-03-01T19:31:04.634373Z",
     "iopub.status.idle": "2024-03-01T19:31:05.268250Z",
     "shell.execute_reply": "2024-03-01T19:31:05.267534Z",
     "shell.execute_reply.started": "2024-03-01T19:31:04.634726Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Nov_22_10:17:15_PST_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.107\n",
      "Build cuda_12.3.r12.3/compiler.33567101_0\n"
     ]
    }
   ],
   "source": [
    "# Check that a cuda environment exists now\n",
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1d62b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:34:24.740595Z",
     "iopub.status.busy": "2024-02-29T22:34:24.740301Z",
     "iopub.status.idle": "2024-02-29T22:34:31.067797Z",
     "shell.execute_reply": "2024-02-29T22:34:31.066976Z",
     "shell.execute_reply.started": "2024-02-29T22:34:24.740572Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-lu5nt0yo\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-lu5nt0yo\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (0.58.1)\n",
      "Requirement already satisfied: numpy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (1.26.3)\n",
      "Requirement already satisfied: torch in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (4.66.1)\n",
      "Requirement already satisfied: more-itertools in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (10.2.0)\n",
      "Requirement already satisfied: tiktoken in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (0.6.0)\n",
      "Requirement already satisfied: triton<3,>=2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (2.1.0)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (2023.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# some dependencies are harder to find. whisper install only worked through git for me\n",
    "! pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9cac8a-ec9a-4602-9e89-3b070fa3baba",
   "metadata": {},
   "source": [
    "## Audio File Transcription\n",
    "\n",
    "As a first stage, let us try to get through whisper and the use of an appropriate external VAD (Silero) to get the transcription of an audio file.\n",
    "Based on this [tutorial](https://colab.research.google.com/github/ANonEntity/WhisperWithVAD/blob/main/WhisperWithVAD.ipynb#scrollTo=sos9vsxPkIN7) where they also use deepl for compatibility with multiple languages. For now we'll assume english for simplicity.\n",
    "\n",
    "Next stage would be to reproduce this result through streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5818d74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T23:27:18.041050Z",
     "iopub.status.busy": "2024-02-28T23:27:18.040532Z",
     "iopub.status.idle": "2024-02-28T23:28:03.834685Z",
     "shell.execute_reply": "2024-02-28T23:28:03.833852Z",
     "shell.execute_reply.started": "2024-02-28T23:27:18.041011Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 23:27:18.641731: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-28 23:27:18.686061: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-28 23:27:18.686091: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-28 23:27:18.687030: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-28 23:27:18.693985: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding audio...\n",
      "Running VAD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/torch/hub.py:294: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /home/jovyan/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Whisper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [00:20<00:00, 74.1MiB/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Subs written to transcription_test.srt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio_path = \"transcription_test.mp3\"\n",
    "model_size = \"medium\"  # [\"medium\", \"large\"]\n",
    "language = \"english\"\n",
    "translation_mode = \"End-to-end Whisper (default)\"  # [\"End-to-end Whisper (default)\", \"Whisper -> DeepL\", \"No translation\"]\n",
    "\n",
    "source_separation = False\n",
    "vad_threshold = 0.4\n",
    "chunk_threshold = 3.0\n",
    "deepl_target_lang = \"EN-US\"\n",
    "max_attempts = 1\n",
    "initial_prompt = \"\"\n",
    "\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import ffmpeg\n",
    "import srt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import whisper\n",
    "from tqdm import tqdm\n",
    "\n",
    "assert max_attempts >= 1\n",
    "assert vad_threshold >= 0.01\n",
    "assert chunk_threshold >= 0.1\n",
    "assert audio_path != \"\"\n",
    "assert language != \"\"\n",
    "\n",
    "\n",
    "task = \"transcribe\"\n",
    "\n",
    "out_path = os.path.splitext(audio_path)[0] + \".srt\"\n",
    "out_path_pre = os.path.splitext(audio_path)[0] + \"_Untranslated.srt\"\n",
    "\n",
    "# if source_separation:\n",
    "#     print(\"Separating vocals...\")\n",
    "#     !ffprobe -i \"{audio_path}\" -show_entries format=duration -v quiet -of csv=\"p=0\" > input_length\n",
    "#     with open(\"input_length\") as f:\n",
    "#         input_length = int(float(f.read())) + 1\n",
    "#     !spleeter separate -d {input_length} -p spleeter:2stems -o output \"{audio_path}\"\n",
    "#     spleeter_dir = os.path.basename(os.path.splitext(audio_path)[0])\n",
    "#     audio_path = \"output/\" + spleeter_dir + \"/vocals.wav\"\n",
    "\n",
    "print(\"Encoding audio...\")\n",
    "if not os.path.exists(\"vad_chunks\"):\n",
    "    os.mkdir(\"vad_chunks\")\n",
    "ffmpeg.input(audio_path).output(\n",
    "    \"vad_chunks/silero_temp.wav\",\n",
    "    ar=\"16000\",\n",
    "    ac=\"1\",\n",
    "    acodec=\"pcm_s16le\",\n",
    "    map_metadata=\"-1\",\n",
    "    fflags=\"+bitexact\",\n",
    ").overwrite_output().run(quiet=True)\n",
    "\n",
    "print(\"Running VAD...\")\n",
    "model, utils = torch.hub.load(\n",
    "    repo_or_dir=\"snakers4/silero-vad\", model=\"silero_vad\", onnx=False\n",
    ")\n",
    "\n",
    "(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils\n",
    "\n",
    "# Generate VAD timestamps\n",
    "VAD_SR = 16000\n",
    "wav = read_audio(\"vad_chunks/silero_temp.wav\", sampling_rate=VAD_SR)\n",
    "t = get_speech_timestamps(wav, model, sampling_rate=VAD_SR, threshold=vad_threshold)\n",
    "\n",
    "# Add a bit of padding, and remove small gaps\n",
    "for i in range(len(t)):\n",
    "    t[i][\"start\"] = max(0, t[i][\"start\"] - 3200)  # 0.2s head\n",
    "    t[i][\"end\"] = min(wav.shape[0] - 16, t[i][\"end\"] + 20800)  # 1.3s tail\n",
    "    if i > 0 and t[i][\"start\"] < t[i - 1][\"end\"]:\n",
    "        t[i][\"start\"] = t[i - 1][\"end\"]  # Remove overlap\n",
    "\n",
    "# If breaks are longer than chunk_threshold seconds, split into a new audio file\n",
    "# This'll effectively turn long transcriptions into many shorter ones\n",
    "u = [[]]\n",
    "for i in range(len(t)):\n",
    "    if i > 0 and t[i][\"start\"] > t[i - 1][\"end\"] + (chunk_threshold * VAD_SR):\n",
    "        u.append([])\n",
    "    u[-1].append(t[i])\n",
    "\n",
    "# Merge speech chunks\n",
    "for i in range(len(u)):\n",
    "    save_audio(\n",
    "        \"vad_chunks/\" + str(i) + \".wav\",\n",
    "        collect_chunks(u[i], wav),\n",
    "        sampling_rate=VAD_SR,\n",
    "    )\n",
    "\n",
    "os.remove(\"vad_chunks/silero_temp.wav\")\n",
    "\n",
    "# Convert timestamps to seconds\n",
    "for i in range(len(u)):\n",
    "    time = 0.0\n",
    "    offset = 0.0\n",
    "    for j in range(len(u[i])):\n",
    "        u[i][j][\"start\"] /= VAD_SR\n",
    "        u[i][j][\"end\"] /= VAD_SR\n",
    "        u[i][j][\"chunk_start\"] = time\n",
    "        time += u[i][j][\"end\"] - u[i][j][\"start\"]\n",
    "        u[i][j][\"chunk_end\"] = time\n",
    "        if j == 0:\n",
    "            offset += u[i][j][\"start\"]\n",
    "        else:\n",
    "            offset += u[i][j][\"start\"] - u[i][j - 1][\"end\"]\n",
    "        u[i][j][\"offset\"] = offset\n",
    "\n",
    "# Run Whisper on each audio chunk\n",
    "print(\"Running Whisper...\")\n",
    "model = whisper.load_model(model_size)\n",
    "subs = []\n",
    "segment_info = []\n",
    "sub_index = 1\n",
    "suppress_low = []  # words to remove\n",
    "suppress_high = []  # words to remove\n",
    "for i in tqdm(range(len(u))):\n",
    "    line_buffer = []  # Used for DeepL\n",
    "    for x in range(max_attempts):\n",
    "        result = model.transcribe(\n",
    "            \"vad_chunks/\" + str(i) + \".wav\",\n",
    "            task=task,\n",
    "            language=language,\n",
    "            initial_prompt=initial_prompt,\n",
    "        )\n",
    "        # Break if result doesn't end with severe hallucinations\n",
    "        if len(result[\"segments\"]) == 0:\n",
    "            break\n",
    "        elif result[\"segments\"][-1][\"end\"] < u[i][-1][\"chunk_end\"] + 10.0:\n",
    "            break\n",
    "        elif x + 1 < max_attempts:\n",
    "            print(\"Retrying chunk\", i)\n",
    "    for r in result[\"segments\"]:\n",
    "        # Skip audio timestamped after the chunk has ended\n",
    "        if r[\"start\"] > u[i][-1][\"chunk_end\"]:\n",
    "            continue\n",
    "        # Reduce log probability for certain words/phrases\n",
    "        for s in suppress_low:\n",
    "            if s in r[\"text\"]:\n",
    "                r[\"avg_logprob\"] -= 0.15\n",
    "        for s in suppress_high:\n",
    "            if s in r[\"text\"]:\n",
    "                r[\"avg_logprob\"] -= 0.35\n",
    "        # Keep segment info for debugging\n",
    "        del r[\"tokens\"]\n",
    "        segment_info.append(r)\n",
    "        # Skip if log prob is low or no speech prob is high\n",
    "        if r[\"avg_logprob\"] < -1.0 or r[\"no_speech_prob\"] > 0.7:\n",
    "            continue\n",
    "        # Set start timestamp\n",
    "        start = r[\"start\"] + u[i][0][\"offset\"]\n",
    "        for j in range(len(u[i])):\n",
    "            if (\n",
    "                r[\"start\"] >= u[i][j][\"chunk_start\"]\n",
    "                and r[\"start\"] <= u[i][j][\"chunk_end\"]\n",
    "            ):\n",
    "                start = r[\"start\"] + u[i][j][\"offset\"]\n",
    "                break\n",
    "        # Prevent overlapping subs\n",
    "        if len(subs) > 0:\n",
    "            last_end = datetime.timedelta.total_seconds(subs[-1].end)\n",
    "            if last_end > start:\n",
    "                subs[-1].end = datetime.timedelta(seconds=start)\n",
    "        # Set end timestamp\n",
    "        end = u[i][-1][\"end\"] + 0.5\n",
    "        for j in range(len(u[i])):\n",
    "            if r[\"end\"] >= u[i][j][\"chunk_start\"] and r[\"end\"] <= u[i][j][\"chunk_end\"]:\n",
    "                end = r[\"end\"] + u[i][j][\"offset\"]\n",
    "                break\n",
    "        # Add to SRT list\n",
    "        subs.append(\n",
    "            srt.Subtitle(\n",
    "                index=sub_index,\n",
    "                start=datetime.timedelta(seconds=start),\n",
    "                end=datetime.timedelta(seconds=end),\n",
    "                content=r[\"text\"].strip(),\n",
    "            )\n",
    "        )\n",
    "        sub_index += 1\n",
    "\n",
    "with open(\"segment_info.json\", \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(segment_info, f, indent=4)\n",
    "\n",
    "# Write SRT file\n",
    "# Removal of garbage lines\n",
    "garbage_list = []\n",
    "need_context_lines = []\n",
    "clean_subs = list()\n",
    "last_line_garbage = False\n",
    "for i in range(len(subs)):\n",
    "    c = subs[i].content\n",
    "    c = (\n",
    "        c.replace(\".\", \"\")\n",
    "        .replace(\",\", \"\")\n",
    "        .replace(\":\", \"\")\n",
    "        .replace(\";\", \"\")\n",
    "        .replace(\"!\", \"\")\n",
    "        .replace(\"?\", \"\")\n",
    "        .replace(\"-\", \" \")\n",
    "        .replace(\"  \", \" \")\n",
    "        .replace(\"  \", \" \")\n",
    "        .replace(\"  \", \" \")\n",
    "        .lower()\n",
    "    )\n",
    "    is_garbage = True\n",
    "    for w in c.split(\" \"):\n",
    "        if w.strip() == \"\":\n",
    "            continue\n",
    "        if w.strip() in garbage_list:\n",
    "            continue\n",
    "        elif w.strip() in need_context_lines and last_line_garbage:\n",
    "            continue\n",
    "        else:\n",
    "            is_garbage = False\n",
    "            break\n",
    "    if not is_garbage:\n",
    "        clean_subs.append(subs[i])\n",
    "    last_line_garbage = is_garbage\n",
    "with open(out_path, \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(srt.compose(clean_subs))\n",
    "print(\"\\nDone! Subs written to\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88b62189-6393-481f-ac58-7e6bba1af208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T19:32:48.195416Z",
     "iopub.status.busy": "2024-03-01T19:32:48.195055Z",
     "iopub.status.idle": "2024-03-01T19:32:48.814195Z",
     "shell.execute_reply": "2024-03-01T19:32:48.813387Z",
     "shell.execute_reply.started": "2024-03-01T19:32:48.195383Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "00:00:01,114 --> 00:00:05,114\n",
      "This is a live recording and a test for live transcription.\n",
      "\n",
      "2\n",
      "00:00:05,114 --> 00:00:10,114\n",
      "My name is Benjamin and I'm talking to you, the avatar.\n",
      "\n",
      "3\n",
      "00:00:10,114 --> 00:00:16,114\n",
      "What I want to know is how many people live in Paris in 2023.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cat transcription_test.srt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b35e72-dc17-4e62-8007-a9ef3ceb8a11",
   "metadata": {},
   "source": [
    " This is a clear success!\n",
    "    \n",
    "Now let us try a similar  technique but from an audio stream\n",
    "\n",
    "## Transcription of a live stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "858f1d4d-f46f-4d51-8086-dde781d1ed08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T23:40:38.744153Z",
     "iopub.status.busy": "2024-02-28T23:40:38.743685Z",
     "iopub.status.idle": "2024-02-28T23:40:39.450493Z",
     "shell.execute_reply": "2024-02-28T23:40:39.448950Z",
     "shell.execute_reply.started": "2024-02-28T23:40:38.744111Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM sysdefault\n",
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM sysdefault\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.front\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround40\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround41\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround50\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround51\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround71\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM default\n",
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM default\n",
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_id returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM dmix\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -9996] Invalid input device (no default output device)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m p \u001b[38;5;241m=\u001b[39m pyaudio\u001b[38;5;241m.\u001b[39mPyAudio()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Open audio stream\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFORMAT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHANNELS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mframes_per_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Initialize Whisper model\u001b[39;00m\n\u001b[1;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/pyaudio/__init__.py:639\u001b[0m, in \u001b[0;36mPyAudio.open\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Opens a new stream.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    See constructor for :py:func:`PyAudio.Stream.__init__` for parameter\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    :returns: A new :py:class:`PyAudio.Stream`\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mPyAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streams\u001b[38;5;241m.\u001b[39madd(stream)\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/pyaudio/__init__.py:441\u001b[0m, in \u001b[0;36mPyAudio.Stream.__init__\u001b[0;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[1;32m    438\u001b[0m     arguments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream_callback\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stream_callback\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# calling pa.open returns a stream object\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_latency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39minputLatency\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_latency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39moutputLatency\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -9996] Invalid input device (no default output device)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import pyaudio\n",
    "import whisper\n",
    "\n",
    "# Define audio stream parameters\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1  # don't need left and right here\n",
    "RATE = 16000  # sampling rate (number of audio samples per second)\n",
    "CHUNK_TIME = 5  # measured in seconds\n",
    "CHUNK = 48000  # number of samples\n",
    "\n",
    "# Create PyAudio object\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open audio stream\n",
    "stream = p.open(\n",
    "    format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK\n",
    ")\n",
    "\n",
    "# Initialize Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "try:\n",
    "    print(\"Start speaking...\")\n",
    "\n",
    "    while True:\n",
    "        data = stream.read(CHUNK)\n",
    "\n",
    "        # Transcribe audio chunk\n",
    "        result = model.transcribe(audio=data)\n",
    "\n",
    "        # Extract text from result and print it **immediately**\n",
    "        print(result[\"text\"])\n",
    "\n",
    "        # Optionally, clear the transcribed text for the next chunk\n",
    "        # (reduces memory usage but discards previous text)\n",
    "        result[\"text\"] = \"\"\n",
    "\n",
    "        # Exit on user input (optional)\n",
    "        if input(\"Press 'q' to quit: \") == \"q\":\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nExiting...\")\n",
    "\n",
    "finally:\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    # Close PyAudio\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b447c-4bc1-4f52-a56b-6e3760766877",
   "metadata": {},
   "source": [
    "Given I am executing this notebook in the cloud, my own machine's microphone is not available.\n",
    "Let us skip this part for now\n",
    "\n",
    "## Getting an avatar \n",
    "\n",
    "We are using  a LLM to reply to the user, than a Text-to-speech approach, then the [MakeItTalk paper](https://github.com/yzhou359/MakeItTalk/blob/main/quick_demo.ipynb) here\n",
    "\n",
    "### First we need to generate an answer\n",
    "We can use any LLM here. Using an API can be fast and avoid any infrastructure cost for  this specific need.\n",
    "Yet using a solution like Mistral or llama could be much faster.\n",
    "\n",
    "Here I will generate the answer using Huggingface's API. [Check it out](https://huggingface.co/mistralai/Mistral-7B-v0.1?text=This+is+a+live+recording+and+a+test+for+live+transcription.%0D%0A+My+name+is+Benjamin+and+Im+talking+to+you%2C+the+avatar.%0D%0A+What+I+want+to+know+is+how+many+people+live+in+Paris+in+2023.)\n",
    "\n",
    "For a commercial product, hosting the model would be possible. Specifically this exercise is about a \"select few numbers of users\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07af3c8-64a2-4a83-83e1-5a70f2adb76a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:34:33.639386Z",
     "iopub.status.busy": "2024-02-29T22:34:33.638977Z",
     "iopub.status.idle": "2024-02-29T22:34:33.645076Z",
     "shell.execute_reply": "2024-02-29T22:34:33.644247Z",
     "shell.execute_reply.started": "2024-02-29T22:34:33.639354Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is a live recording and a test for live transcription.\n",
      " My name is Benjamin and Im talking to you, the avatar.\n",
      " What I want to know is how many people live in Paris in 2023.\n"
     ]
    }
   ],
   "source": [
    "# %cd ../\n",
    "import json\n",
    "\n",
    "with open(\"segment_info.json\", \"r+\") as f:\n",
    "    j = json.load(f)\n",
    "question = \"\\n\".join([e[\"text\"].replace('\"', \"\").replace(\"'\", \"\") for e in j])\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f359b2d-bb9d-4742-9c56-883c82b81f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "\n",
    "# # Replace \"YOUR_API_KEY\" with your actual OpenAI API key\n",
    "# openai.api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "# response = openai.Completion.create(\n",
    "#     engine=\"text-davinci-003\",  # Choose the appropriate model\n",
    "#     prompt=question,\n",
    "#     max_tokens=100,  # Limit response length (optional)\n",
    "#     temperature=0.5,  # Control creativity (optional)\n",
    "# )\n",
    "\n",
    "## Alternatively\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Install the required libraries:\n",
    "# pip install transformers\n",
    "\n",
    "# Load the Mistral model and tokenizer\n",
    "# model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# # Encode the prompt into a format the model understandsé\n",
    "# input_ids = tokenizer.encode(question, return_tensors=\"pt\")\n",
    "\n",
    "# # Generate text using the model (beam search with 3 beams)\n",
    "# output = model.generate(\n",
    "#     input_ids=input_ids,\n",
    "#     max_length=50,  # Adjust the maximum generated text length\n",
    "#     num_beams=3,\n",
    "# )\n",
    "\n",
    "# # Decode the generated tokens back into text\n",
    "# response = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22333d68-78be-4b2a-a34e-8aee5580c208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T19:33:01.132195Z",
     "iopub.status.busy": "2024-03-01T19:33:01.131805Z",
     "iopub.status.idle": "2024-03-01T19:33:01.135980Z",
     "shell.execute_reply": "2024-03-01T19:33:01.135262Z",
     "shell.execute_reply.started": "2024-03-01T19:33:01.132165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assumed response\n",
    "response = \"\"\"\n",
    "Based on the information I have access to. As of January 1, 2023, the estimated population of Paris is:\n",
    "\n",
    "2,102,650 residents (source: statista.com)\n",
    "It's important to note that population data can change over time, so it's always recommended to refer to reliable sources for the most up-to-date information.\n",
    "\n",
    "I hope this information is helpful!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c556d6-148a-4cbe-b83c-c070bd7ef095",
   "metadata": {},
   "source": [
    "### Then we need to create a voice sample based on the text we got out\n",
    "\n",
    "We could use [voice-cloning](https://www.adrianbulat.com/downloads/python-fan) but will stick to Google TTS API for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4253149-e14d-4eb6-a17a-8b7f16207fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T19:33:05.922598Z",
     "iopub.status.busy": "2024-03-01T19:33:05.921966Z",
     "iopub.status.idle": "2024-03-01T19:33:50.474157Z",
     "shell.execute_reply": "2024-03-01T19:33:50.473338Z",
     "shell.execute_reply.started": "2024-03-01T19:33:05.922567Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for: ['gtts']\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "pkgs/main/linux-64 (check zst) \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m   0.0 B Checking  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64 (check zst)                      Checked  0.1s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/noarch (check zst)                       Checked  0.0s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/linux-64 (check zst)                        Checked  0.0s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/noarch (check zst)                          Checked  0.0s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/noarch                                   703.9kB @   7.3MB/s  0.1s\n",
      "[+] 0.1s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/main/linux-64   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m  53.7kB /   5.9MB @   1.0MB/s  0.1s\n",
      "pkgs/r/linux-64      \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/r/noarch        \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/linux-64                                      1.6MB @  10.8MB/s  0.2s\n",
      "pkgs/r/noarch                                        2.1MB @  10.6MB/s  0.1s\n",
      "[+] 0.2s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 454.0kB /  32.8MB @   2.7MB/s  0.2s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 441.4kB /  13.7MB @   2.5MB/s  0.2s\n",
      "pkgs/main/linux-64   ━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━\u001b[0m   5.2MB /   5.9MB @  27.4MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64                                   5.9MB @  28.1MB/s  0.2s\n",
      "[+] 0.3s\n",
      "conda-forge/linux-64 ━━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m   5.5MB /  32.8MB @  19.0MB/s  0.3s\n",
      "conda-forge/noarch   ━━━╸\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m   2.8MB /  13.7MB @  11.6MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\n",
      "conda-forge/linux-64 ━━━━╸\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m   8.6MB /  32.8MB @  25.1MB/s  0.4s\n",
      "conda-forge/noarch   ━━━━━━━━━━━━━╸\u001b[90m━━━━━━━━━\u001b[0m   8.8MB /  13.7MB @  24.6MB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                  13.7MB @  30.8MB/s  0.4s\n",
      "[+] 0.5s\n",
      "conda-forge/linux-64 ━━━━━━━━━╸\u001b[90m━━━━━━━━━━━━━\u001b[0m  15.0MB /  32.8MB @  32.6MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━╸\u001b[90m━━━━━\u001b[0m  26.4MB /  32.8MB @  45.0MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                                32.8MB @  49.3MB/s  0.7s\n",
      "\u001b[?25h\n",
      "Pinned packages:\n",
      "  - python 3.10.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/saturncloud/envs/saturn\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - gtts\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package  Version  Build         Channel         Size\n",
      "────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[32m+ gtts \u001b[0m    2.5.1  pyhd8ed1ab_0  conda-forge     35kB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 1 packages\n",
      "\n",
      "  Total download: 35kB\n",
      "\n",
      "────────────────────────────────────────────────────────\n",
      "\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "Downloading      \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B                            0.0s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "Downloading  (1) \u001b[33m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B gtts                       0.0s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n",
      "Downloading  (1) \u001b[33m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B gtts                       0.1s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ggtts                                                34.6kB @ 125.8kB/s  0.3s\n",
      "[+] 0.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  34.6kB                            0.2s\n",
      "Extracting   (1) \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m       0 gtts                       0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "! mamba install -y gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b6375bb-179f-49a3-8e16-5129cfe19c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:12:32.696168Z",
     "iopub.status.busy": "2024-02-29T22:12:32.695775Z",
     "iopub.status.idle": "2024-02-29T22:12:35.478803Z",
     "shell.execute_reply": "2024-02-29T22:12:35.478081Z",
     "shell.execute_reply.started": "2024-02-29T22:12:32.696142Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "# Define language and speed (optional)\n",
    "tts = gTTS(text=response, lang=\"en\", slow=False)\n",
    "\n",
    "# Save audio file\n",
    "tts.save(\"reply.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616eec8-e956-42cb-801a-48b3a5ff1e7e",
   "metadata": {},
   "source": [
    "Alternatively let us do something funnier involving voice-cloning using [tortoise tts](https://blog.paperspace.com/how-to-quickly-clone-your-voice-with-tortoise-text-to-speech/#:~:text=Tortoise%20TTS,-Released%20by%20solo&text=It%20makes%20it%20easy%20to,and%20Denoising%20Diffusion%20Probabilistic%20Models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e592e2d8-8b28-4bb7-869a-069d5b2b342b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T19:34:02.006228Z",
     "iopub.status.busy": "2024-03-01T19:34:02.005845Z",
     "iopub.status.idle": "2024-03-01T19:34:10.120014Z",
     "shell.execute_reply": "2024-03-01T19:34:10.119277Z",
     "shell.execute_reply.started": "2024-03-01T19:34:02.006197Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt-dlp in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (2023.12.30)\n",
      "Requirement already satisfied: TTS in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: mutagen in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from yt-dlp) (1.47.0)\n",
      "Requirement already satisfied: pycryptodomex in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from yt-dlp) (3.20.0)\n",
      "Requirement already satisfied: certifi in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from yt-dlp) (2024.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.31.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from yt-dlp) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from yt-dlp) (1.26.18)\n",
      "Requirement already satisfied: websockets>=12.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from yt-dlp) (12.0)\n",
      "Requirement already satisfied: brotli in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from yt-dlp) (1.1.0)\n",
      "Requirement already satisfied: cython>=0.29.30 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (3.0.8)\n",
      "Requirement already satisfied: scipy>=1.11.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (1.11.4)\n",
      "Requirement already satisfied: torch>=2.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (2.1.0)\n",
      "Requirement already satisfied: torchaudio in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (2.1.0)\n",
      "Requirement already satisfied: soundfile>=0.12.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.12.1)\n",
      "Requirement already satisfied: librosa>=0.10.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (1.4.0)\n",
      "Requirement already satisfied: inflect>=5.6.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (7.0.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (4.66.1)\n",
      "Requirement already satisfied: anyascii>=0.3.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.3.2)\n",
      "Requirement already satisfied: pyyaml>=6.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.6.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (2023.12.2)\n",
      "Requirement already satisfied: aiohttp>=3.8.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (3.9.1)\n",
      "Requirement already satisfied: packaging>=23.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (23.2)\n",
      "Requirement already satisfied: flask>=2.0.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (3.0.2)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.3.4)\n",
      "Requirement already satisfied: umap-learn>=0.5.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.5.5)\n",
      "Requirement already satisfied: pandas<2.0,>=1.4 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (1.5.3)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (3.8.2)\n",
      "Requirement already satisfied: trainer>=0.0.32 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.0.36)\n",
      "Requirement already satisfied: coqpit>=0.0.16 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.0.17)\n",
      "Requirement already satisfied: jieba in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.42.1)\n",
      "Requirement already satisfied: pypinyin in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.50.0)\n",
      "Requirement already satisfied: hangul-romanize in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.1.0)\n",
      "Requirement already satisfied: gruut==2.2.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.2.3)\n",
      "Requirement already satisfied: jamo in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.4.1)\n",
      "Requirement already satisfied: nltk in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (3.8.1)\n",
      "Requirement already satisfied: g2pkk>=0.1.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.1.2)\n",
      "Requirement already satisfied: bangla in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.0.2)\n",
      "Requirement already satisfied: bnnumerizer in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.0.2)\n",
      "Requirement already satisfied: bnunicodenormalizer in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.1.6)\n",
      "Requirement already satisfied: einops>=0.6.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.7.0)\n",
      "Requirement already satisfied: transformers>=4.33.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (4.38.2)\n",
      "Requirement already satisfied: encodec>=0.1.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.1.1)\n",
      "Requirement already satisfied: unidecode>=1.3.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (1.3.8)\n",
      "Requirement already satisfied: num2words in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.5.13)\n",
      "Requirement already satisfied: spacy>=3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy[ja]>=3->TTS) (3.7.2)\n",
      "Requirement already satisfied: numpy==1.22.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (1.22.0)\n",
      "Requirement already satisfied: numba>=0.57.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from TTS) (0.58.1)\n",
      "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.14.0)\n",
      "Requirement already satisfied: dateparser~=1.1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.1.8)\n",
      "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (0.13.0)\n",
      "Requirement already satisfied: gruut-lang-en~=2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
      "Requirement already satisfied: jsonlines~=1.2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.2.0)\n",
      "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.8.8)\n",
      "Requirement already satisfied: python-crfsuite~=0.9.7 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (0.9.10)\n",
      "Requirement already satisfied: gruut-lang-de~=2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
      "Requirement already satisfied: gruut-lang-es~=2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
      "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (4.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from flask>=2.0.1->TTS) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from flask>=2.0.1->TTS) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from flask>=2.0.1->TTS) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from flask>=2.0.1->TTS) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from flask>=2.0.1->TTS) (1.7.0)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from inflect>=5.6.0->TTS) (2.5.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from inflect>=5.6.0->TTS) (4.9.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (1.0.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (2.8.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from num2words->TTS) (0.6.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from numba>=0.57.0->TTS) (0.41.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pandas<2.0,>=1.4->TTS) (2023.3.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests<3,>=2.31.0->yt-dlp) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests<3,>=2.31.0->yt-dlp) (3.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from scikit-learn>=1.3.0->TTS) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from soundfile>=0.12.0->TTS) (1.16.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (5.2.1)\n",
      "Requirement already satisfied: setuptools in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (69.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.3.0)\n",
      "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy[ja]>=3->TTS) (0.6.8)\n",
      "Requirement already satisfied: sudachidict-core>=20211220 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy[ja]>=3->TTS) (20240109)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=2.1->TTS) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=2.1->TTS) (1.12)\n",
      "Requirement already satisfied: psutil in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from trainer>=0.0.32->TTS) (5.9.8)\n",
      "Requirement already satisfied: tensorboard in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from trainer>=0.0.32->TTS) (2.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers>=4.33.0->TTS) (0.21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers>=4.33.0->TTS) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers>=4.33.0->TTS) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers>=4.33.0->TTS) (0.4.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from umap-learn>=0.5.1->TTS) (0.5.11)\n",
      "Requirement already satisfied: pycparser in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.21)\n",
      "Requirement already satisfied: tzlocal in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (5.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask>=2.0.1->TTS) (2.1.4)\n",
      "Requirement already satisfied: six in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pooch>=1.0->librosa>=0.10.0->TTS) (4.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect>=5.6.0->TTS) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect>=5.6.0->TTS) (2.14.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy>=3->spacy[ja]>=3->TTS) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy>=3->spacy[ja]>=3->TTS) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (0.16.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sympy->torch>=2.1->TTS) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (1.59.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (3.5.2)\n",
      "Requirement already satisfied: protobuf in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (4.24.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS) (3.2.2)\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=GI8kwPe6Uek\n",
      "[youtube] GI8kwPe6Uek: Downloading webpage\n",
      "[youtube] GI8kwPe6Uek: Downloading ios player API JSON\n",
      "[youtube] GI8kwPe6Uek: Downloading android player API JSON\n",
      "[youtube] GI8kwPe6Uek: Downloading m3u8 information\n",
      "[info] GI8kwPe6Uek: Downloading 1 format(s): 251\n",
      "[download] macron_audio_sample.wav has already been downloaded\n",
      "[ExtractAudio] Destination: macron_audio_sample.wav\n",
      "Deleting original file macron_audio_sample.orig.wav (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "! pip install yt-dlp TTS\n",
    "! yt-dlp -f \"ba\" -o \"macron_audio_sample.%(ext)s\" --extract-audio --audio-format wav --audio-quality 0 \"https://www.youtube.com/watch?v=GI8kwPe6Uek\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da616d84-8cfb-4f7a-8dd1-5ac76b2f3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to solve broken links in model downloads https://github.com/coqui-ai/TTS/issues/2686\n",
    "! export TRAINER_TELEMETRY=0\n",
    "! cd /opt/saturncloud/envs/saturn/lib/python3.10/site-packages/TTS && cp .models.json .models.json.bak && \n",
    "# ! wget -P ~/.local/share/tts/tts_models--multilingual--multi-dataset--your_tts https://github.com/coqui-ai/TTS/releases/download/v0.10.1_models/tts_models--multilingual--multi-dataset--your_tts.zip\n",
    "# ! unzip ~/.local/share/tts/tts_models--multilingual--multi-dataset--your_tts/tts_models--multilingual--multi-dataset--your_tts.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e42fd055-5e43-4e5f-8db0-00f01f1da7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:28:55.635186Z",
     "iopub.status.busy": "2024-03-01T20:28:55.634808Z",
     "iopub.status.idle": "2024-03-01T20:29:08.648482Z",
     "shell.execute_reply": "2024-03-01T20:29:08.647719Z",
     "shell.execute_reply.started": "2024-03-01T20:28:55.635156Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading model to /home/jovyan/.local/share/tts/tts_models--multilingual--multi-dataset--your_tts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190M/190M [04:30<00:00, 703kiB/s]\n",
      "100%|█████████▉| 423M/425M [00:03<00:00, 126MiB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model's license - CC BY-NC-ND 4.0\n",
      " > Check https://creativecommons.org/licenses/by-nc-nd/4.0/ for more info.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > External Speaker Encoder Loaded !!\n",
      " > initialization of language-embedding layers.\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > Text splitted to sentences.\n",
      "['Based on the information I have access to.', 'As of January 1, 2023, the estimated population of Paris is:', '2,102,650 residents (source: statista.com)', \"It's important to note that population data can change over time, so it's always recommended to refer to reliable sources for the most up-to-date information.\", 'I hope this information is helpful!']\n",
      "as of january 1, 2023, the estimated population of paris is,\n",
      " [!] Character '1' not found in the vocabulary. Discarding it.\n",
      "as of january 1, 2023, the estimated population of paris is,\n",
      " [!] Character '2' not found in the vocabulary. Discarding it.\n",
      "as of january 1, 2023, the estimated population of paris is,\n",
      " [!] Character '0' not found in the vocabulary. Discarding it.\n",
      "as of january 1, 2023, the estimated population of paris is,\n",
      " [!] Character '3' not found in the vocabulary. Discarding it.\n",
      "2,102,650 residents source, statista.com\n",
      " [!] Character '6' not found in the vocabulary. Discarding it.\n",
      "2,102,650 residents source, statista.com\n",
      " [!] Character '5' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 2.550687074661255\n",
      " > Real-time factor: 0.10492768417710538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'macron_generated.wav'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 425M/425M [00:19<00:00, 126MiB/s]"
     ]
    }
   ],
   "source": [
    "# tts = TTS(\"tts_models/fr/mai/tacotron2-DDC\")\n",
    "# tts.tts_with_vc_to_file(\n",
    "#     response,\n",
    "#     speaker_wav=\"macron_audio_sample.wav\",\n",
    "#     file_path='macron_generated.wav'\n",
    "# )\n",
    "\n",
    "from TTS.api import TTS\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", progress_bar=True).to(\"cuda\") # \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "tts.tts_to_file(response, speaker_wav=\"macron_audio_sample.wav\", file_path=\"macron_generated.wav\", language=\"en\") #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a33d0f-e65f-4111-9e1f-180f87c0d869",
   "metadata": {},
   "source": [
    "### Then we need to create the animation and reproduce it\n",
    "Here using [MakeItTalk tutorial](https://github.com/yzhou359/MakeItTalk/blob/main/quick_demo.ipynb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f68451d-3983-461c-bb6f-de712be9b9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:29:46.927344Z",
     "iopub.status.busy": "2024-03-01T20:29:46.926948Z",
     "iopub.status.idle": "2024-03-01T20:30:46.790729Z",
     "shell.execute_reply": "2024-03-01T20:30:46.789928Z",
     "shell.execute_reply.started": "2024-03-01T20:29:46.927316Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (4.9.0)\n",
      "Collecting face_alignment\n",
      "  Downloading face_alignment-1.4.1-py2.py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (1.4.0)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: soundfile in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (0.12.1)\n",
      "Collecting librosa==0.9.1\n",
      "  Downloading librosa-0.9.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pysptk\n",
      "  Downloading pysptk-0.2.2.tar.gz (421 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.3/421.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyworld\n",
      "  Downloading pyworld-0.3.4.tar.gz (251 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.0/252.0 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting resemblyzer\n",
      "  Downloading Resemblyzer-0.1.4-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting pynormalize\n",
      "  Downloading pynormalize-0.1.4-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa==0.9.1) (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa==0.9.1) (1.22.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa==0.9.1) (1.11.4)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa==0.9.1) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa==0.9.1) (5.1.1)\n",
      "Collecting resampy>=0.2.2 (from librosa==0.9.1)\n",
      "  Downloading resampy-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numba>=0.45.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa==0.9.1) (0.58.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa==0.9.1) (1.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa==0.9.1) (23.2)\n",
      "Requirement already satisfied: torch in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from face_alignment) (2.1.0)\n",
      "Collecting scikit-image (from face_alignment)\n",
      "  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tqdm in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from face_alignment) (4.66.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: cython>=0.28.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pysptk) (3.0.8)\n",
      "Collecting webrtcvad>=2.0.10 (from resemblyzer)\n",
      "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing (from resemblyzer)\n",
      "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboardX) (4.24.4)\n",
      "Requirement already satisfied: mutagen>=1.40.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pynormalize) (1.47.0)\n",
      "Requirement already satisfied: pycparser in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from numba>=0.45.1->librosa==0.9.1) (0.41.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.9.1) (4.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.9.1) (2.31.0)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->face_alignment) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->face_alignment) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->face_alignment) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->face_alignment) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->face_alignment) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->face_alignment) (2023.12.2)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from scikit-image->face_alignment) (10.2.0)\n",
      "Collecting imageio>=2.27 (from scikit-image->face_alignment)\n",
      "  Downloading imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->face_alignment)\n",
      "  Downloading tifffile-2024.2.12-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from scikit-image->face_alignment) (0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from jinja2->torch->face_alignment) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sympy->torch->face_alignment) (1.3.0)\n",
      "Downloading librosa-0.9.1-py3-none-any.whl (213 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading face_alignment-1.4.1-py2.py3-none-any.whl (30 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading Resemblyzer-0.1.4-py3-none-any.whl (15.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pysptk, pyworld, webrtcvad, typing\n",
      "  Building wheel for pysptk (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pysptk: filename=pysptk-0.2.2-cp310-cp310-linux_x86_64.whl size=392166 sha256=ee45648d01c9e9351097561169dd979c275c468ed9e7cbc78fcf8dd9dfe3de4c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/87/ef/11/e708873d0361690e25e06ccfd1d793ff4549a91bb48ee58ca3\n",
      "  Building wheel for pyworld (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyworld: filename=pyworld-0.3.4-cp310-cp310-linux_x86_64.whl size=202745 sha256=5719b2e47274857e4c24f1e341bbb3cb8b2ea79d5acc7b1dfe12c76523f1fcb2\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/66/09/8a/a1d79b73d59756f66e9bfe55a199840efc7473adb76ddacdfd\n",
      "  Building wheel for webrtcvad (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp310-cp310-linux_x86_64.whl size=26962 sha256=bba4c5ddfbce9dc06d8f32c082b58524ae3c589e17f728973f9fcc4e99d2a697\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/2a/2b/84/ac7bacfe8c68a87c1ee3dd3c66818a54c71599abf308e8eb35\n",
      "  Building wheel for typing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26304 sha256=1fc875630aa87d6810e706da96ff42857e3d504b3cf35653b79b8ea6e7883236\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/7c/d0/9e/1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\n",
      "Successfully built pysptk pyworld webrtcvad typing\n",
      "Installing collected packages: webrtcvad, pydub, typing, tifffile, tensorboardX, pyworld, pynormalize, imageio, scikit-image, resampy, pysptk, librosa, face_alignment, resemblyzer\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.10.0\n",
      "    Uninstalling librosa-0.10.0:\n",
      "      Successfully uninstalled librosa-0.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tts 0.22.0 requires librosa>=0.10.0, but you have librosa 0.9.1 which is incompatible.\n",
      "tortoise-tts 3.0.0 requires transformers==4.31.0, but you have transformers 4.38.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed face_alignment-1.4.1 imageio-2.34.0 librosa-0.9.1 pydub-0.25.1 pynormalize-0.1.4 pysptk-0.2.2 pyworld-0.3.4 resampy-0.4.2 resemblyzer-0.1.4 scikit-image-0.22.0 tensorboardX-2.6.2.2 tifffile-2024.2.12 typing-3.7.4.3 webrtcvad-2.0.10\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python face_alignment scikit-learn pydub soundfile librosa==0.9.1 pysptk pyworld resemblyzer tensorboardX pynormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf942a75-6771-467f-8b29-2673fbc274ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:35:07.609196Z",
     "iopub.status.busy": "2024-02-29T22:35:07.608776Z",
     "iopub.status.idle": "2024-02-29T22:35:08.212511Z",
     "shell.execute_reply": "2024-02-29T22:35:08.211656Z",
     "shell.execute_reply.started": "2024-02-29T22:35:07.609167Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/yzhou359/MakeItTalk\n",
    "! export PYTHONPATH=MakeItTalk:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2e3d2c8-6468-49da-bd5a-bc7ee96b480b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:35:13.737931Z",
     "iopub.status.busy": "2024-02-29T22:35:13.737543Z",
     "iopub.status.idle": "2024-02-29T22:35:46.866582Z",
     "shell.execute_reply": "2024-02-29T22:35:46.865460Z",
     "shell.execute_reply.started": "2024-02-29T22:35:13.737905Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘MakeItTalk/examples/dump’: File exists\n",
      "mkdir: cannot create directory ‘MakeItTalk/examples/ckpt’: File exists\n",
      "Requirement already satisfied: gdown in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (5.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gdown) (4.66.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests[socks]->gdown) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
      "From (redirected): https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x&confirm=t&uuid=ce64cde6-b090-486e-8436-fced2f9bc42d\n",
      "To: /home/jovyan/workspace/MakeItTalk/examples/ckpt/ckpt_autovc.pth\n",
      "100%|████████████████████████████████████████| 172M/172M [00:01<00:00, 87.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
      "To: /home/jovyan/workspace/MakeItTalk/examples/ckpt/ckpt_content_branch.pth\n",
      "100%|██████████████████████████████████████| 7.88M/7.88M [00:00<00:00, 45.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
      "To: /home/jovyan/workspace/MakeItTalk/examples/ckpt/ckpt_speaker_branch.pth\n",
      "100%|██████████████████████████████████████| 15.4M/15.4M [00:00<00:00, 60.1MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
      "From (redirected): https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a&confirm=t&uuid=0034bba6-cdbc-4301-bb07-db73555a9f41\n",
      "To: /home/jovyan/workspace/MakeItTalk/examples/ckpt/ckpt_116_i2i_comb.pth\n",
      "100%|█████████████████████████████████████████| 839M/839M [00:06<00:00, 135MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI\n",
      "To: /home/jovyan/workspace/MakeItTalk/examples/dump/emb.pickle\n",
      "100%|██████████████████████████████████████| 30.9M/30.9M [00:02<00:00, 13.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "! mkdir MakeItTalk/examples/dump\n",
    "! mkdir MakeItTalk/examples/ckpt\n",
    "! pip install gdown\n",
    "! gdown -O MakeItTalk/examples/ckpt/ckpt_autovc.pth https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
    "! gdown -O MakeItTalk/examples/ckpt/ckpt_content_branch.pth https://drive.google.com/uc?id=1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
    "! gdown -O MakeItTalk/examples/ckpt/ckpt_speaker_branch.pth https://drive.google.com/uc?id=1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
    "! gdown -O MakeItTalk/examples/ckpt/ckpt_116_i2i_comb.pth https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
    "! gdown -O MakeItTalk/examples/dump/emb.pickle https://drive.google.com/uc?id=18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fa3e3-000f-433e-b52d-a643331d3aca",
   "metadata": {},
   "source": [
    "# IMPORTANT\n",
    "adapt MakeItTalk/thirdparty/AdaptativeWingLoss/core/models.py\n",
    "You want line 5 to be `from ..core.coord_conv import CoordConvTh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd48aa2a-ae7f-4d63-b467-c14677abbe6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T23:07:05.506443Z",
     "iopub.status.busy": "2024-02-29T23:07:05.506034Z",
     "iopub.status.idle": "2024-02-29T23:07:05.521923Z",
     "shell.execute_reply": "2024-02-29T23:07:05.521052Z",
     "shell.execute_reply.started": "2024-02-29T23:07:05.506415Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633 633\n"
     ]
    }
   ],
   "source": [
    "# You can use any picture you like but it has to be 256x256 size. Here I need to adapt the size of my \"macron\" picture.\n",
    "from PIL import Image\n",
    "\n",
    "# Define input and output image paths (replace with your actual paths)\n",
    "input_path = \"../macron_square.jpg\"\n",
    "output_path = \"../macron_square_resized.jpg\"\n",
    "\n",
    "# Define the desired size for the resized image\n",
    "new_size = 256  # Adjust the size as needed\n",
    "\n",
    "# Open the image\n",
    "image = Image.open(input_path)\n",
    "print(image.height, image.width)\n",
    "resized_image = image.resize((new_size, new_size))\n",
    "resized_image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2086edbc-d83d-4658-a45f-92daf07ffb50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:33:54.196526Z",
     "iopub.status.busy": "2024-03-01T20:33:54.196156Z",
     "iopub.status.idle": "2024-03-01T20:33:58.170873Z",
     "shell.execute_reply": "2024-03-01T20:33:58.170224Z",
     "shell.execute_reply.started": "2024-03-01T20:33:54.196495Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workspace/MakeItTalk\n"
     ]
    }
   ],
   "source": [
    "%cd MakeItTalk/\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"thirdparty/AdaptiveWingLoss\")\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import face_alignment\n",
    "import numpy as np\n",
    "import torch\n",
    "import util.utils as util\n",
    "from scipy.signal import savgol_filter\n",
    "from src.approaches.train_audio2landmark import Audio2landmark_model\n",
    "from src.approaches.train_image_translation import Image_translation_block\n",
    "from src.autovc.AutoVC_mel_Convertor_retrain_version import AutoVC_mel_Convertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5aa6ef-ba45-43d9-80bc-07462a011eca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:34:30.011868Z",
     "iopub.status.busy": "2024-03-01T20:34:30.011477Z",
     "iopub.status.idle": "2024-03-01T20:34:30.015719Z",
     "shell.execute_reply": "2024-03-01T20:34:30.015073Z",
     "shell.execute_reply.started": "2024-03-01T20:34:30.011840Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_head_name = \"macron_square_resized\" #\"paint_boy\"  # the image name (with no .jpg) to animate\n",
    "ADD_NAIVE_EYE = True  # whether add naive eye blink\n",
    "CLOSE_INPUT_FACE_MOUTH = (\n",
    "    False  # if your image has an opened mouth, put this as True, else False\n",
    ")\n",
    "AMP_LIP_SHAPE_X = 2.0  # amplify the lip motion in horizontal direction\n",
    "AMP_LIP_SHAPE_Y = 2.0  # amplify the lip motion in vertical direction\n",
    "AMP_HEAD_POSE_MOTION = 0.7  # amplify the head pose motion (usually smaller than 1.0, put it to 0. for a static head pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ce9f68-033b-4e27-a9e2-dab9785a6c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:34:32.050327Z",
     "iopub.status.busy": "2024-03-01T20:34:32.049918Z",
     "iopub.status.idle": "2024-03-01T20:34:32.062927Z",
     "shell.execute_reply": "2024-03-01T20:34:32.062340Z",
     "shell.execute_reply.started": "2024-03-01T20:34:32.050279Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--jpg\", type=str, default=\"../{}.jpg\".format(default_head_name))\n",
    "parser.add_argument(\n",
    "    \"--close_input_face_mouth\", default=CLOSE_INPUT_FACE_MOUTH, action=\"store_true\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--load_AUTOVC_name\", type=str, default=\"examples/ckpt/ckpt_autovc.pth\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--load_a2l_G_name\", type=str, default=\"examples/ckpt/ckpt_speaker_branch.pth\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--load_a2l_C_name\", type=str, default=\"examples/ckpt/ckpt_content_branch.pth\"\n",
    ")  # ckpt_audio2landmark_c.pth')\n",
    "parser.add_argument(\n",
    "    \"--load_G_name\", type=str, default=\"examples/ckpt/ckpt_116_i2i_comb.pth\"\n",
    ")  # ckpt_image2image.pth') #ckpt_i2i_finetune_150.pth') #c\n",
    "\n",
    "parser.add_argument(\"--amp_lip_x\", type=float, default=AMP_LIP_SHAPE_X)\n",
    "parser.add_argument(\"--amp_lip_y\", type=float, default=AMP_LIP_SHAPE_Y)\n",
    "parser.add_argument(\"--amp_pos\", type=float, default=AMP_HEAD_POSE_MOTION)\n",
    "parser.add_argument(\n",
    "    \"--reuse_train_emb_list\", type=str, nargs=\"+\", default=[]\n",
    ")  #  ['iWeklsXc0H8']) #['45hn7-LXDX8']) #['E_kmpT-EfOg']) #'iWeklsXc0H8', '29k8RtSUjE0', '45hn7-LXDX8',\n",
    "parser.add_argument(\"--add_audio_in\", default=False, action=\"store_true\")\n",
    "parser.add_argument(\"--comb_fan_awing\", default=False, action=\"store_true\")\n",
    "parser.add_argument(\"--output_folder\", type=str, default=\"examples\")\n",
    "\n",
    "parser.add_argument(\"--test_end2end\", default=True, action=\"store_true\")\n",
    "parser.add_argument(\"--dump_dir\", type=str, default=\"\", help=\"\")\n",
    "parser.add_argument(\"--pos_dim\", default=7, type=int)\n",
    "parser.add_argument(\"--use_prior_net\", default=True, action=\"store_true\")\n",
    "parser.add_argument(\"--transformer_d_model\", default=32, type=int)\n",
    "parser.add_argument(\"--transformer_N\", default=2, type=int)\n",
    "parser.add_argument(\"--transformer_heads\", default=2, type=int)\n",
    "parser.add_argument(\"--spk_emb_enc_size\", default=16, type=int)\n",
    "parser.add_argument(\"--init_content_encoder\", type=str, default=\"\")\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-3, help=\"learning rate\")\n",
    "parser.add_argument(\"--reg_lr\", type=float, default=1e-6, help=\"weight decay\")\n",
    "parser.add_argument(\"--write\", default=False, action=\"store_true\")\n",
    "parser.add_argument(\"--segment_batch_size\", type=int, default=1, help=\"batch size\")\n",
    "parser.add_argument(\"--emb_coef\", default=3.0, type=float)\n",
    "parser.add_argument(\"--lambda_laplacian_smooth_loss\", default=1.0, type=float)\n",
    "parser.add_argument(\"--use_11spk_only\", default=False, action=\"store_true\")\n",
    "parser.add_argument(\"-f\")\n",
    "\n",
    "opt_parser = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afed81bc-9c50-450f-b34e-b2b6cefd2def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T21:31:23.403273Z",
     "iopub.status.busy": "2024-02-29T21:31:23.402857Z",
     "iopub.status.idle": "2024-02-29T21:31:24.049314Z",
     "shell.execute_reply": "2024-02-29T21:31:24.048355Z",
     "shell.execute_reply.started": "2024-02-29T21:31:23.403243Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In case of network errors in the next cell,\n",
    "# manually copy file \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/s3fd-619a316812.pth\n",
    "# \"https://www.adrianbulat.com/downloads/python-fan/3DFAN4-4a694010b9.zip\" to /home/jovyan/.cache/torch/hub/checkpoints/3DFAN4-4a694010b9.zip\n",
    "# \"https://www.adrianbulat.com/downloads/python-fan/depth-6c4283c0e0.zip\" to /home/jovyan/.cache/torch/hub/checkpoints/depth-6c4283c0e0.zip\n",
    "# ! mv ../s3fd-619a316812.pth /home/jovyan/.cache/torch/hub/checkpoints/\n",
    "# ! mv ../3DFAN4-4a694010b9.zip /home/jovyan/.cache/torch/hub/checkpoints/\n",
    "# ! mv ../depth-6c4283c0e0.zip /home/jovyan/.cache/torch/hub/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca86dbe4-fa19-4803-936c-6e25cc74c5eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:34:35.279138Z",
     "iopub.status.busy": "2024-03-01T20:34:35.278726Z",
     "iopub.status.idle": "2024-03-01T20:34:49.150411Z",
     "shell.execute_reply": "2024-03-01T20:34:49.149717Z",
     "shell.execute_reply.started": "2024-03-01T20:34:35.279108Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(opt_parser.jpg)\n",
    "predictor = face_alignment.FaceAlignment(\n",
    "    face_alignment.LandmarksType.THREE_D, device=\"cuda\", flip_input=True\n",
    ")\n",
    "shapes = predictor.get_landmarks(img)\n",
    "if not shapes or len(shapes) != 1:\n",
    "    print(\"Cannot detect face landmarks. Exit.\")\n",
    "    exit(-1)\n",
    "shape_3d = shapes[0]\n",
    "\n",
    "if opt_parser.close_input_face_mouth:\n",
    "    util.close_input_face_mouth(shape_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6f56022-f516-4f01-be2c-e86f7cfc59a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:50:44.905458Z",
     "iopub.status.busy": "2024-02-29T22:50:44.905033Z",
     "iopub.status.idle": "2024-02-29T22:50:44.910430Z",
     "shell.execute_reply": "2024-02-29T22:50:44.909609Z",
     "shell.execute_reply.started": "2024-02-29T22:50:44.905428Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shape_3d[48:, 0] = (shape_3d[48:, 0] - np.mean(shape_3d[48:, 0])) * 1.05 + np.mean(shape_3d[48:, 0]) # wider lips\n",
    "# shape_3d[49:54, 1] += 0.           # thinner upper lip\n",
    "# shape_3d[55:60, 1] -= 1.           # thinner lower lip\n",
    "# shape_3d[[37,38,43,44], 1] -=2.    # larger eyes\n",
    "# shape_3d[[40,41,46,47], 1] +=2.    # larger eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d71c3d28-63a1-43fe-82fe-bfcef0639932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:34:49.152618Z",
     "iopub.status.busy": "2024-03-01T20:34:49.152007Z",
     "iopub.status.idle": "2024-03-01T20:34:49.157227Z",
     "shell.execute_reply": "2024-03-01T20:34:49.156466Z",
     "shell.execute_reply.started": "2024-03-01T20:34:49.152578Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape_3d, scale, shift = util.norm_input_face(shape_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a53d1b5-d931-43aa-af0b-e2fd5cdee7f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:48:32.634946Z",
     "iopub.status.busy": "2024-02-29T22:48:32.634557Z",
     "iopub.status.idle": "2024-02-29T22:48:33.355086Z",
     "shell.execute_reply": "2024-02-29T22:48:33.354290Z",
     "shell.execute_reply.started": "2024-02-29T22:48:32.634919Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.3.0 (conda-forge gcc 12.3.0-3)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_build_env/bin/pkg-config\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "\u001b[0;35m[mp3 @ 0x559c330e6b40] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
      "\u001b[0mInput #0, mp3, from 'examples/reply.mp3':\n",
      "  Duration: 00:00:30.26, start: 0.000000, bitrate: 32 kb/s\n",
      "  Stream #0:0: Audio: mp3, 24000 Hz, mono, fltp, 32 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'examples/reply.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf60.16.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.31.102 pcm_s16le\n",
      "\u001b[1;35m[out#0/wav @ 0x559c330e8cc0] \u001b[0mvideo:0kB audio:1419kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.005369%\n",
      "size=    1419kB time=00:00:30.24 bitrate= 384.3kbits/s speed= 559x    \n"
     ]
    }
   ],
   "source": [
    "# ! cp ../reply.mp3 examples\n",
    "# ! ffmpeg -i examples/reply.mp3 examples/reply.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "887a6226-afab-4c6f-884f-678f9bfa8abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:34:49.159197Z",
     "iopub.status.busy": "2024-03-01T20:34:49.158601Z",
     "iopub.status.idle": "2024-03-01T20:34:51.038876Z",
     "shell.execute_reply": "2024-03-01T20:34:51.038045Z",
     "shell.execute_reply.started": "2024-03-01T20:34:49.159160Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the voice encoder model on cuda in 0.02 seconds.\n",
      "Processing audio file macron_generated.wav\n",
      "0 out of 0 are in this portion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workspace/MakeItTalk/src/autovc/retrain_version/vocoder_spec/extract_f0_func.py:97: FutureWarning: Pass sr=16000, n_fft=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = mel(16000, 1024, fmin=90, fmax=7600, n_mels=80).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the voice encoder model on cuda in 0.02 seconds.\n",
      "source shape: torch.Size([1, 1536, 80]) torch.Size([1, 256]) torch.Size([1, 256]) torch.Size([1, 1536, 257])\n",
      "converted shape: torch.Size([1, 1536, 80]) torch.Size([1, 3072])\n"
     ]
    }
   ],
   "source": [
    "au_data = []\n",
    "au_emb = []\n",
    "ains = glob.glob1(\"examples\", \"*.wav\")\n",
    "ains = [item for item in ains if item != \"tmp.wav\"]\n",
    "ains.sort()\n",
    "for ain in ains:\n",
    "    os.system(\n",
    "        \"ffmpeg -y -loglevel error -i examples/{} -ar 16000 examples/tmp.wav\".format(\n",
    "            ain\n",
    "        )\n",
    "    )\n",
    "    shutil.copyfile(\"examples/tmp.wav\", \"examples/{}\".format(ain))\n",
    "\n",
    "    # au embedding\n",
    "    from thirdparty.resemblyer_util.speaker_emb import get_spk_emb\n",
    "\n",
    "    me, ae = get_spk_emb(\"examples/{}\".format(ain))\n",
    "    au_emb.append(me.reshape(-1))\n",
    "\n",
    "    print(\"Processing audio file\", ain)\n",
    "    c = AutoVC_mel_Convertor(\"examples\")\n",
    "\n",
    "    au_data_i = c.convert_single_wav_to_autovc_input(\n",
    "        audio_filename=os.path.join(\"examples\", ain),\n",
    "        autovc_model_path=opt_parser.load_AUTOVC_name,\n",
    "    )\n",
    "    au_data += au_data_i\n",
    "if os.path.isfile(\"examples/tmp.wav\"):\n",
    "    os.remove(\"examples/tmp.wav\")\n",
    "\n",
    "# landmark fake placeholder\n",
    "fl_data = []\n",
    "rot_tran, rot_quat, anchor_t_shape = [], [], []\n",
    "for au, info in au_data:\n",
    "    au_length = au.shape[0]\n",
    "    fl = np.zeros(shape=(au_length, 68 * 3))\n",
    "    fl_data.append((fl, info))\n",
    "    rot_tran.append(np.zeros(shape=(au_length, 3, 4)))\n",
    "    rot_quat.append(np.zeros(shape=(au_length, 4)))\n",
    "    anchor_t_shape.append(np.zeros(shape=(au_length, 68 * 3)))\n",
    "\n",
    "if os.path.exists(os.path.join(\"examples\", \"dump\", \"random_val_fl.pickle\")):\n",
    "    os.remove(os.path.join(\"examples\", \"dump\", \"random_val_fl.pickle\"))\n",
    "if os.path.exists(os.path.join(\"examples\", \"dump\", \"random_val_fl_interp.pickle\")):\n",
    "    os.remove(os.path.join(\"examples\", \"dump\", \"random_val_fl_interp.pickle\"))\n",
    "if os.path.exists(os.path.join(\"examples\", \"dump\", \"random_val_au.pickle\")):\n",
    "    os.remove(os.path.join(\"examples\", \"dump\", \"random_val_au.pickle\"))\n",
    "if os.path.exists(os.path.join(\"examples\", \"dump\", \"random_val_gaze.pickle\")):\n",
    "    os.remove(os.path.join(\"examples\", \"dump\", \"random_val_gaze.pickle\"))\n",
    "\n",
    "with open(os.path.join(\"examples\", \"dump\", \"random_val_fl.pickle\"), \"wb\") as fp:\n",
    "    pickle.dump(fl_data, fp)\n",
    "with open(os.path.join(\"examples\", \"dump\", \"random_val_au.pickle\"), \"wb\") as fp:\n",
    "    pickle.dump(au_data, fp)\n",
    "with open(os.path.join(\"examples\", \"dump\", \"random_val_gaze.pickle\"), \"wb\") as fp:\n",
    "    gaze = {\n",
    "        \"rot_trans\": rot_tran,\n",
    "        \"rot_quat\": rot_quat,\n",
    "        \"anchor_t_shape\": anchor_t_shape,\n",
    "    }\n",
    "    pickle.dump(gaze, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f2c0a4-1d20-437c-ae44-b8edabbc8acb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:34:57.720932Z",
     "iopub.status.busy": "2024-03-01T20:34:57.720369Z",
     "iopub.status.idle": "2024-03-01T20:35:04.051160Z",
     "shell.execute_reply": "2024-03-01T20:35:04.050126Z",
     "shell.execute_reply.started": "2024-03-01T20:34:57.720902Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workspace/MakeItTalk\n",
      "Run on device: cuda\n",
      "Loading Data random_val\n",
      "EVAL num videos: 1\n",
      "G: Running on cuda, total num params = 3.00M\n",
      "======== LOAD PRETRAINED FACE ID MODEL examples/ckpt/ckpt_speaker_branch.pth =========\n",
      "======== LOAD PRETRAINED FACE ID MODEL examples/ckpt/ckpt_content_branch.pth =========\n",
      "====================================\n",
      "48uYS3bHIA8\n",
      "YAZuSHvwVC0\n",
      "0yaLdVk_UyQ\n",
      "E_kmpT-EfOg\n",
      "fQR31F7L3ww\n",
      "JPMZAOGGHh8\n",
      "W6uRNCJmdtI\n",
      "2KL8PfQPmBg\n",
      "p575B7k07a8\n",
      "iUoAe2gXKE4\n",
      "HH-iOC056aQ\n",
      "S8fiWqrZEew\n",
      "ROWN2ssXek8\n",
      "irx71tYyI-Q\n",
      "me6cdZCM2FY\n",
      "OkqHtWOFliM\n",
      "OfPKHc6w2vw\n",
      "1lh57VnuaKE\n",
      "_ldiVrXgZKc\n",
      "H1Xnb_rtgqY\n",
      "45hn7-LXDX8\n",
      "bs7ZWVqAGCU\n",
      "UElg0R7fmlk\n",
      "bCs5SoifsiY\n",
      "1Lx_ZqrK1bM\n",
      "RrnL6Pcjjbw\n",
      "sRbWv2R2hxE\n",
      "wJmdE0G4sEg\n",
      "hE-4e1vEiT8\n",
      "XXbxe3fCQqg\n",
      "02HOKnTjBlQ\n",
      "wAAMEC1OsRc\n",
      "7Sk--XzX8b0\n",
      "I5Lm0Qce5kg\n",
      "qLxfiUMYgQg\n",
      "_VpqWkdcaqM\n",
      "ljIkW4uVVQY\n",
      "5m5iPZNJS6c\n",
      "J-NPsvtQ8lE\n",
      "gOrQyrbptGo\n",
      "43BiUVlNy58\n",
      "swLghyvhoqA\n",
      "X3FCAoFnmdA\n",
      "2NiCRAmwoc4\n",
      "KVUf0J2LAaA\n",
      "YtZS9hH1j24\n",
      "5fZj9Fzi5K0\n",
      "wbWKG26ebMw\n",
      "QgNlXur0wrs\n",
      "qek_5m1MRik\n",
      "rmFsUV5ICKk\n",
      "bEdGv1wixF4\n",
      "ljh5PB6Utsc\n",
      "izudwWTXuUk\n",
      "B08yOvYMF7Y\n",
      "UEmI4r5G-5Y\n",
      "Scujgl9GbHA\n",
      "sxCbrYjBsGA\n",
      "qvQC0w3y_Fo\n",
      "bXpavyiCu10\n",
      "iWeklsXc0H8\n",
      "H00oAfd_GsM\n",
      "Z7WRt--g-h4\n",
      "29k8RtSUjE0\n",
      "E0zgrhQ0QDw\n",
      "9KhvSxKE6Mc\n",
      "qLNvRwMkhik\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workspace/MakeItTalk/src/approaches/train_audio2landmark.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = torch.tensor(torch.zeros(aus.shape[0], 128), requires_grad=False, dtype=torch.float).to(device)\n",
      "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples/macron_generated.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.3.0 (conda-forge gcc 12.3.0-3)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1705436738391/_build_env/bin/pkg-config\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'examples/tmp.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Duration: 00:00:16.00, start: 0.000000, bitrate: 5440 kb/s\n",
      "  Stream #0:0[0x1](und): Video: mjpeg (Baseline) (mp4v / 0x7634706D), yuvj420p(pc, bt470bg/unknown/unknown), 400x400, 5438 kb/s, 62.50 fps, 62.50 tbr, 10k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "[aist#1:0/pcm_s16le @ 0x56204bdd8d40] Guessed Channel Layout: mono\n",
      "Input #1, wav, from 'examples/macron_generated.wav':\n",
      "  Duration: 00:00:24.31, bitrate: 256 kb/s\n",
      "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x56204bde8d40] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "[libx264 @ 0x56204bde8d40] profile High, level 3.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0x56204bde8d40] 264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'examples/macron_generated_av.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 400x400, q=2-31, 62.50 fps, 16k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 16000 Hz, mono, fltp, 69 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.31.102 aac\n",
      "[out#0/mp4 @ 0x56204bdb1e80] video:610kB audio:130kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.159907%\n",
      "frame= 1000 fps=461 q=-1.0 Lsize=     756kB time=00:00:15.95 bitrate= 388.1kbits/s speed=7.36x    \n",
      "[libx264 @ 0x56204bde8d40] frame I:4     Avg QP: 9.67  size:  4990\n",
      "[libx264 @ 0x56204bde8d40] frame P:262   Avg QP:24.37  size:  1253\n",
      "[libx264 @ 0x56204bde8d40] frame B:734   Avg QP:31.55  size:   375\n",
      "[libx264 @ 0x56204bde8d40] consecutive B-frames:  1.4%  1.2%  3.0% 94.4%\n",
      "[libx264 @ 0x56204bde8d40] mb I  I16..4: 67.0% 20.4% 12.6%\n",
      "[libx264 @ 0x56204bde8d40] mb P  I16..4:  0.6%  1.9%  0.1%  P16..4:  6.8%  4.4%  2.0%  0.0%  0.0%    skip:84.1%\n",
      "[libx264 @ 0x56204bde8d40] mb B  I16..4:  0.2%  0.3%  0.0%  B16..8:  9.6%  2.1%  0.7%  direct: 0.2%  skip:86.8%  L0:52.3% L1:46.2% BI: 1.5%\n",
      "[libx264 @ 0x56204bde8d40] 8x8 transform intra:54.0% inter:7.4%\n",
      "[libx264 @ 0x56204bde8d40] coded y,uvDC,uvAC intra: 3.7% 15.7% 11.8% inter: 1.2% 3.4% 3.1%\n",
      "[libx264 @ 0x56204bde8d40] i16 v,h,dc,p: 72% 24%  3%  0%\n",
      "[libx264 @ 0x56204bde8d40] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  6%  9% 85%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x56204bde8d40] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 21% 37% 23%  2%  2%  2%  6%  1%  6%\n",
      "[libx264 @ 0x56204bde8d40] i8c dc,h,v,p: 52% 29% 18%  0%\n",
      "[libx264 @ 0x56204bde8d40] Weighted P-Frames: Y:5.7% UV:0.0%\n",
      "[libx264 @ 0x56204bde8d40] ref P L0: 47.2% 15.6% 18.7% 17.3%  1.2%\n",
      "[libx264 @ 0x56204bde8d40] ref B L0: 77.6% 16.9%  5.6%\n",
      "[libx264 @ 0x56204bde8d40] ref B L1: 91.6%  8.4%\n",
      "[libx264 @ 0x56204bde8d40] kb/s:311.74\n",
      "[aac @ 0x56204bdf2bc0] Qavg: 36887.305\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "model = Audio2landmark_model(opt_parser, jpg_shape=shape_3d)\n",
    "if(len(opt_parser.reuse_train_emb_list) == 0):\n",
    "    model.test(au_emb=au_emb)\n",
    "else:\n",
    "    model.test(au_emb=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3866605c-86ea-4375-950d-63a826173282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:35:09.277222Z",
     "iopub.status.busy": "2024-03-01T20:35:09.276785Z",
     "iopub.status.idle": "2024-03-01T20:35:56.127206Z",
     "shell.execute_reply": "2024-03-01T20:35:56.126367Z",
     "shell.execute_reply.started": "2024-03-01T20:35:09.277188Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x67706a6d/'mjpg' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time - only video: 35.54931044578552\n",
      "Time - ffmpeg add audio: 40.77012372016907\n",
      "finish image2image gen\n"
     ]
    }
   ],
   "source": [
    "fls = glob.glob1('examples', 'pred_fls_*.txt')\n",
    "fls.sort()\n",
    "\n",
    "for i in range(0,len(fls)):\n",
    "    fl = np.loadtxt(os.path.join('examples', fls[i])).reshape((-1, 68,3))\n",
    "    fl[:, :, 0:2] = -fl[:, :, 0:2]\n",
    "    fl[:, :, 0:2] = fl[:, :, 0:2] / scale - shift\n",
    "\n",
    "    if (ADD_NAIVE_EYE):\n",
    "        fl = util.add_naive_eye(fl)\n",
    "\n",
    "    # additional smooth\n",
    "    fl = fl.reshape((-1, 204))\n",
    "    fl[:, :48 * 3] = savgol_filter(fl[:, :48 * 3], 15, 3, axis=0)\n",
    "    fl[:, 48*3:] = savgol_filter(fl[:, 48*3:], 5, 3, axis=0)\n",
    "    fl = fl.reshape((-1, 68, 3))\n",
    "\n",
    "    ''' STEP 6: Imag2image translation '''\n",
    "    model = Image_translation_block(opt_parser, single_test=True)\n",
    "    with torch.no_grad():\n",
    "        model.single_test(jpg=img, fls=fl, filename=fls[i], prefix=opt_parser.jpg.split('.')[0])\n",
    "        print('finish image2image gen')\n",
    "    os.remove(os.path.join('examples', fls[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
