{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8df51c-537e-48c5-a735-af1c8951f590",
   "metadata": {},
   "source": [
    "# End-to-End Solution\n",
    "\n",
    "This notebook is built assuming a GPU environment is available.\n",
    "This is of course just a jupyter demo, but cuda should be enabled.\n",
    "\n",
    "If using a free  jupyter notebook environment, use a T4 GPU environment. You can even [open a terminal now](https://blog.infuseai.io/run-a-full-tty-terminal-in-google-colab-without-colab-pro-2759b9f8a74a)\n",
    "\n",
    "## Dependencies management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1513937d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/bin/mamba\n",
      "/bin/bash: line 1: nvcc: command not found\n"
     ]
    }
   ],
   "source": [
    "# pick a dependency solver.\n",
    "# here I use saturn cloud (Google Colab GPU ran out on me) and mamba is preinstalled\n",
    "# I usually pick mamba, poetry and uv\n",
    "! which mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339906d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "! mamba install -y tensorflow-gpu ffmpeg ffmpeg-python srt pytorch torchvision torchaudio pytorch-cuda>=12 pyaudio -c pytorch -c nvidia -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58dc7e5-54b9-4673-9f84-c1ca77eb895e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T23:30:21.199514Z",
     "iopub.status.busy": "2024-02-28T23:30:21.198959Z",
     "iopub.status.idle": "2024-02-28T23:30:21.885662Z",
     "shell.execute_reply": "2024-02-28T23:30:21.884710Z",
     "shell.execute_reply.started": "2024-02-28T23:30:21.199463Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Nov_22_10:17:15_PST_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.107\n",
      "Build cuda_12.3.r12.3/compiler.33567101_0\n"
     ]
    }
   ],
   "source": [
    "# Check that a cuda environment exists now\n",
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed1d62b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-oraczcbm\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-oraczcbm\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (0.58.1)\n",
      "Requirement already satisfied: numpy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (1.26.3)\n",
      "Requirement already satisfied: torch in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (4.66.1)\n",
      "Collecting more-itertools (from openai-whisper==20231117)\n",
      "  Downloading more_itertools-10.2.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tiktoken (from openai-whisper==20231117)\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: triton<3,>=2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from openai-whisper==20231117) (2.1.0)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (2023.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
      "Downloading more_itertools-10.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=a630fa0a06d4b4c0af497eb213154950c196eff62f57ca3ef5ae54a7e33f8cc3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-asfmjcpf/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: more-itertools, tiktoken, openai-whisper\n",
      "Successfully installed more-itertools-10.2.0 openai-whisper-20231117 tiktoken-0.6.0\n"
     ]
    }
   ],
   "source": [
    "# some dependencies are harder to find. whisper install only worked through git for me\n",
    "! pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9cac8a-ec9a-4602-9e89-3b070fa3baba",
   "metadata": {},
   "source": [
    "## Audio File Transcription\n",
    "\n",
    "As a first stage, let us try to get through whisper and the use of an appropriate external VAD (Silero) to get the transcription of an audio file.\n",
    "Based on this [tutorial](https://colab.research.google.com/github/ANonEntity/WhisperWithVAD/blob/main/WhisperWithVAD.ipynb#scrollTo=sos9vsxPkIN7) where they also use deepl for compatibility with multiple languages. For now we'll assume english for simplicity.\n",
    "\n",
    "Next stage would be to reproduce this result through streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5818d74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T23:27:18.041050Z",
     "iopub.status.busy": "2024-02-28T23:27:18.040532Z",
     "iopub.status.idle": "2024-02-28T23:28:03.834685Z",
     "shell.execute_reply": "2024-02-28T23:28:03.833852Z",
     "shell.execute_reply.started": "2024-02-28T23:27:18.041011Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 23:27:18.641731: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-28 23:27:18.686061: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-28 23:27:18.686091: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-28 23:27:18.687030: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-28 23:27:18.693985: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding audio...\n",
      "Running VAD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/torch/hub.py:294: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /home/jovyan/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Whisper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [00:20<00:00, 74.1MiB/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Subs written to transcription_test.srt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio_path = \"transcription_test.mp3\"\n",
    "model_size = \"medium\"  # [\"medium\", \"large\"]\n",
    "language = \"english\"\n",
    "translation_mode = \"End-to-end Whisper (default)\"  # [\"End-to-end Whisper (default)\", \"Whisper -> DeepL\", \"No translation\"]\n",
    "\n",
    "source_separation = False\n",
    "vad_threshold = 0.4\n",
    "chunk_threshold = 3.0\n",
    "deepl_target_lang = \"EN-US\"\n",
    "max_attempts = 1\n",
    "initial_prompt = \"\"\n",
    "\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import ffmpeg\n",
    "import srt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import whisper\n",
    "from tqdm import tqdm\n",
    "\n",
    "assert max_attempts >= 1\n",
    "assert vad_threshold >= 0.01\n",
    "assert chunk_threshold >= 0.1\n",
    "assert audio_path != \"\"\n",
    "assert language != \"\"\n",
    "\n",
    "\n",
    "task = \"transcribe\"\n",
    "\n",
    "out_path = os.path.splitext(audio_path)[0] + \".srt\"\n",
    "out_path_pre = os.path.splitext(audio_path)[0] + \"_Untranslated.srt\"\n",
    "\n",
    "# if source_separation:\n",
    "#     print(\"Separating vocals...\")\n",
    "#     !ffprobe -i \"{audio_path}\" -show_entries format=duration -v quiet -of csv=\"p=0\" > input_length\n",
    "#     with open(\"input_length\") as f:\n",
    "#         input_length = int(float(f.read())) + 1\n",
    "#     !spleeter separate -d {input_length} -p spleeter:2stems -o output \"{audio_path}\"\n",
    "#     spleeter_dir = os.path.basename(os.path.splitext(audio_path)[0])\n",
    "#     audio_path = \"output/\" + spleeter_dir + \"/vocals.wav\"\n",
    "\n",
    "print(\"Encoding audio...\")\n",
    "if not os.path.exists(\"vad_chunks\"):\n",
    "    os.mkdir(\"vad_chunks\")\n",
    "ffmpeg.input(audio_path).output(\n",
    "    \"vad_chunks/silero_temp.wav\",\n",
    "    ar=\"16000\",\n",
    "    ac=\"1\",\n",
    "    acodec=\"pcm_s16le\",\n",
    "    map_metadata=\"-1\",\n",
    "    fflags=\"+bitexact\",\n",
    ").overwrite_output().run(quiet=True)\n",
    "\n",
    "print(\"Running VAD...\")\n",
    "model, utils = torch.hub.load(\n",
    "    repo_or_dir=\"snakers4/silero-vad\", model=\"silero_vad\", onnx=False\n",
    ")\n",
    "\n",
    "(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils\n",
    "\n",
    "# Generate VAD timestamps\n",
    "VAD_SR = 16000\n",
    "wav = read_audio(\"vad_chunks/silero_temp.wav\", sampling_rate=VAD_SR)\n",
    "t = get_speech_timestamps(wav, model, sampling_rate=VAD_SR, threshold=vad_threshold)\n",
    "\n",
    "# Add a bit of padding, and remove small gaps\n",
    "for i in range(len(t)):\n",
    "    t[i][\"start\"] = max(0, t[i][\"start\"] - 3200)  # 0.2s head\n",
    "    t[i][\"end\"] = min(wav.shape[0] - 16, t[i][\"end\"] + 20800)  # 1.3s tail\n",
    "    if i > 0 and t[i][\"start\"] < t[i - 1][\"end\"]:\n",
    "        t[i][\"start\"] = t[i - 1][\"end\"]  # Remove overlap\n",
    "\n",
    "# If breaks are longer than chunk_threshold seconds, split into a new audio file\n",
    "# This'll effectively turn long transcriptions into many shorter ones\n",
    "u = [[]]\n",
    "for i in range(len(t)):\n",
    "    if i > 0 and t[i][\"start\"] > t[i - 1][\"end\"] + (chunk_threshold * VAD_SR):\n",
    "        u.append([])\n",
    "    u[-1].append(t[i])\n",
    "\n",
    "# Merge speech chunks\n",
    "for i in range(len(u)):\n",
    "    save_audio(\n",
    "        \"vad_chunks/\" + str(i) + \".wav\",\n",
    "        collect_chunks(u[i], wav),\n",
    "        sampling_rate=VAD_SR,\n",
    "    )\n",
    "\n",
    "os.remove(\"vad_chunks/silero_temp.wav\")\n",
    "\n",
    "# Convert timestamps to seconds\n",
    "for i in range(len(u)):\n",
    "    time = 0.0\n",
    "    offset = 0.0\n",
    "    for j in range(len(u[i])):\n",
    "        u[i][j][\"start\"] /= VAD_SR\n",
    "        u[i][j][\"end\"] /= VAD_SR\n",
    "        u[i][j][\"chunk_start\"] = time\n",
    "        time += u[i][j][\"end\"] - u[i][j][\"start\"]\n",
    "        u[i][j][\"chunk_end\"] = time\n",
    "        if j == 0:\n",
    "            offset += u[i][j][\"start\"]\n",
    "        else:\n",
    "            offset += u[i][j][\"start\"] - u[i][j - 1][\"end\"]\n",
    "        u[i][j][\"offset\"] = offset\n",
    "\n",
    "# Run Whisper on each audio chunk\n",
    "print(\"Running Whisper...\")\n",
    "model = whisper.load_model(model_size)\n",
    "subs = []\n",
    "segment_info = []\n",
    "sub_index = 1\n",
    "suppress_low = []  # words to remove\n",
    "suppress_high = []  # words to remove\n",
    "for i in tqdm(range(len(u))):\n",
    "    line_buffer = []  # Used for DeepL\n",
    "    for x in range(max_attempts):\n",
    "        result = model.transcribe(\n",
    "            \"vad_chunks/\" + str(i) + \".wav\",\n",
    "            task=task,\n",
    "            language=language,\n",
    "            initial_prompt=initial_prompt,\n",
    "        )\n",
    "        # Break if result doesn't end with severe hallucinations\n",
    "        if len(result[\"segments\"]) == 0:\n",
    "            break\n",
    "        elif result[\"segments\"][-1][\"end\"] < u[i][-1][\"chunk_end\"] + 10.0:\n",
    "            break\n",
    "        elif x + 1 < max_attempts:\n",
    "            print(\"Retrying chunk\", i)\n",
    "    for r in result[\"segments\"]:\n",
    "        # Skip audio timestamped after the chunk has ended\n",
    "        if r[\"start\"] > u[i][-1][\"chunk_end\"]:\n",
    "            continue\n",
    "        # Reduce log probability for certain words/phrases\n",
    "        for s in suppress_low:\n",
    "            if s in r[\"text\"]:\n",
    "                r[\"avg_logprob\"] -= 0.15\n",
    "        for s in suppress_high:\n",
    "            if s in r[\"text\"]:\n",
    "                r[\"avg_logprob\"] -= 0.35\n",
    "        # Keep segment info for debugging\n",
    "        del r[\"tokens\"]\n",
    "        segment_info.append(r)\n",
    "        # Skip if log prob is low or no speech prob is high\n",
    "        if r[\"avg_logprob\"] < -1.0 or r[\"no_speech_prob\"] > 0.7:\n",
    "            continue\n",
    "        # Set start timestamp\n",
    "        start = r[\"start\"] + u[i][0][\"offset\"]\n",
    "        for j in range(len(u[i])):\n",
    "            if (\n",
    "                r[\"start\"] >= u[i][j][\"chunk_start\"]\n",
    "                and r[\"start\"] <= u[i][j][\"chunk_end\"]\n",
    "            ):\n",
    "                start = r[\"start\"] + u[i][j][\"offset\"]\n",
    "                break\n",
    "        # Prevent overlapping subs\n",
    "        if len(subs) > 0:\n",
    "            last_end = datetime.timedelta.total_seconds(subs[-1].end)\n",
    "            if last_end > start:\n",
    "                subs[-1].end = datetime.timedelta(seconds=start)\n",
    "        # Set end timestamp\n",
    "        end = u[i][-1][\"end\"] + 0.5\n",
    "        for j in range(len(u[i])):\n",
    "            if r[\"end\"] >= u[i][j][\"chunk_start\"] and r[\"end\"] <= u[i][j][\"chunk_end\"]:\n",
    "                end = r[\"end\"] + u[i][j][\"offset\"]\n",
    "                break\n",
    "        # Add to SRT list\n",
    "        subs.append(\n",
    "            srt.Subtitle(\n",
    "                index=sub_index,\n",
    "                start=datetime.timedelta(seconds=start),\n",
    "                end=datetime.timedelta(seconds=end),\n",
    "                content=r[\"text\"].strip(),\n",
    "            )\n",
    "        )\n",
    "        sub_index += 1\n",
    "\n",
    "with open(\"segment_info.json\", \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(segment_info, f, indent=4)\n",
    "\n",
    "# Write SRT file\n",
    "# Removal of garbage lines\n",
    "garbage_list = []\n",
    "need_context_lines = []\n",
    "clean_subs = list()\n",
    "last_line_garbage = False\n",
    "for i in range(len(subs)):\n",
    "    c = subs[i].content\n",
    "    c = (\n",
    "        c.replace(\".\", \"\")\n",
    "        .replace(\",\", \"\")\n",
    "        .replace(\":\", \"\")\n",
    "        .replace(\";\", \"\")\n",
    "        .replace(\"!\", \"\")\n",
    "        .replace(\"?\", \"\")\n",
    "        .replace(\"-\", \" \")\n",
    "        .replace(\"  \", \" \")\n",
    "        .replace(\"  \", \" \")\n",
    "        .replace(\"  \", \" \")\n",
    "        .lower()\n",
    "    )\n",
    "    is_garbage = True\n",
    "    for w in c.split(\" \"):\n",
    "        if w.strip() == \"\":\n",
    "            continue\n",
    "        if w.strip() in garbage_list:\n",
    "            continue\n",
    "        elif w.strip() in need_context_lines and last_line_garbage:\n",
    "            continue\n",
    "        else:\n",
    "            is_garbage = False\n",
    "            break\n",
    "    if not is_garbage:\n",
    "        clean_subs.append(subs[i])\n",
    "    last_line_garbage = is_garbage\n",
    "with open(out_path, \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(srt.compose(clean_subs))\n",
    "print(\"\\nDone! Subs written to\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b62189-6393-481f-ac58-7e6bba1af208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T23:35:35.617595Z",
     "iopub.status.busy": "2024-02-28T23:35:35.617144Z",
     "iopub.status.idle": "2024-02-28T23:35:36.297044Z",
     "shell.execute_reply": "2024-02-28T23:35:36.296078Z",
     "shell.execute_reply.started": "2024-02-28T23:35:35.617562Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "00:00:01,114 --> 00:00:05,114\n",
      "This is a live recording and a test for live transcription.\n",
      "\n",
      "2\n",
      "00:00:05,114 --> 00:00:10,114\n",
      "My name is Benjamin and I'm talking to you, the avatar.\n",
      "\n",
      "3\n",
      "00:00:10,114 --> 00:00:16,114\n",
      "What I want to know is how many people live in Paris in 2023.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cat transcription_test.srt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b35e72-dc17-4e62-8007-a9ef3ceb8a11",
   "metadata": {},
   "source": [
    " This is a clear success!\n",
    "    \n",
    "Now let us try a similar  technique but from an audio stream\n",
    "\n",
    "## Transcription of a live stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "858f1d4d-f46f-4d51-8086-dde781d1ed08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T23:40:38.744153Z",
     "iopub.status.busy": "2024-02-28T23:40:38.743685Z",
     "iopub.status.idle": "2024-02-28T23:40:39.450493Z",
     "shell.execute_reply": "2024-02-28T23:40:39.448950Z",
     "shell.execute_reply.started": "2024-02-28T23:40:38.744111Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM sysdefault\n",
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM sysdefault\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.front\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround40\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround41\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround50\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround51\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround71\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM default\n",
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM default\n",
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_id returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM dmix\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -9996] Invalid input device (no default output device)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m p \u001b[38;5;241m=\u001b[39m pyaudio\u001b[38;5;241m.\u001b[39mPyAudio()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Open audio stream\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFORMAT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHANNELS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mframes_per_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Initialize Whisper model\u001b[39;00m\n\u001b[1;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/pyaudio/__init__.py:639\u001b[0m, in \u001b[0;36mPyAudio.open\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Opens a new stream.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    See constructor for :py:func:`PyAudio.Stream.__init__` for parameter\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    :returns: A new :py:class:`PyAudio.Stream`\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mPyAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streams\u001b[38;5;241m.\u001b[39madd(stream)\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/pyaudio/__init__.py:441\u001b[0m, in \u001b[0;36mPyAudio.Stream.__init__\u001b[0;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[1;32m    438\u001b[0m     arguments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream_callback\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stream_callback\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# calling pa.open returns a stream object\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_latency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39minputLatency\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_latency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39moutputLatency\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -9996] Invalid input device (no default output device)"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import whisper\n",
    "import time\n",
    "\n",
    "# Define audio stream parameters\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1 # don't need left and right here\n",
    "RATE = 16000 # sampling rate (number of audio samples per second)\n",
    "CHUNK_TIME = 5 # measured in seconds\n",
    "CHUNK = 48000 # number of samples\n",
    "\n",
    "# Create PyAudio object\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open audio stream\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "# Initialize Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "try:\n",
    "    print(\"Start speaking...\")\n",
    "\n",
    "    while True:\n",
    "        data = stream.read(CHUNK)\n",
    "\n",
    "        # Transcribe audio chunk\n",
    "        result = model.transcribe(audio=data)\n",
    "\n",
    "        # Extract text from result and print it **immediately**\n",
    "        print(result[\"text\"])\n",
    "\n",
    "        # Optionally, clear the transcribed text for the next chunk\n",
    "        # (reduces memory usage but discards previous text)\n",
    "        result[\"text\"] = \"\"\n",
    "\n",
    "        # Exit on user input (optional)\n",
    "        if input(\"Press 'q' to quit: \") == \"q\":\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nExiting...\")\n",
    "\n",
    "finally:\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    # Close PyAudio\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eec227-16cf-419f-9c1d-64ba1c614779",
   "metadata": {},
   "source": [
    "Given I am executing this notebook in the cloud, my own machine's microphone is not available.\n",
    "Let us skip this part for now\n",
    "\n",
    "## Getting an avatar \n",
    "\n",
    "We are using the [MakeItTalk paper]() here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f68451d-3983-461c-bb6f-de712be9b9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T23:59:40.084601Z",
     "iopub.status.busy": "2024-02-28T23:59:40.084156Z",
     "iopub.status.idle": "2024-02-28T23:59:46.167917Z",
     "shell.execute_reply": "2024-02-28T23:59:46.167035Z",
     "shell.execute_reply.started": "2024-02-28T23:59:40.084564Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (4.9.0)\n",
      "Collecting face_alignment\n",
      "  Using cached face_alignment-1.4.1-py2.py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (1.4.0)\n",
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting soundfile\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
      "Collecting librosa\n",
      "  Using cached librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pysptk\n",
      "  Using cached pysptk-0.2.2-cp310-cp310-linux_x86_64.whl\n",
      "Collecting pyworld\n",
      "  Using cached pyworld-0.3.4-cp310-cp310-linux_x86_64.whl\n",
      "Collecting resemblyzer\n",
      "  Using cached Resemblyzer-0.1.4-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: torch in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from face_alignment) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from face_alignment) (1.26.3)\n",
      "Requirement already satisfied: scipy>=0.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from face_alignment) (1.12.0)\n",
      "Collecting scikit-image (from face_alignment)\n",
      "  Using cached scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tqdm in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from face_alignment) (4.66.1)\n",
      "Requirement already satisfied: numba in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from face_alignment) (0.58.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from soundfile) (1.16.0)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Collecting pooch>=1.0 (from librosa)\n",
      "  Using cached pooch-1.8.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Using cached soxr-0.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa) (4.9.0)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Using cached lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from librosa) (1.0.7)\n",
      "Collecting cython>=0.28.0 (from pysptk)\n",
      "  Using cached Cython-3.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting webrtcvad>=2.0.10 (from resemblyzer)\n",
      "  Using cached webrtcvad-2.0.10-cp310-cp310-linux_x86_64.whl\n",
      "Collecting typing (from resemblyzer)\n",
      "  Using cached typing-3.7.4.3-py3-none-any.whl\n",
      "Requirement already satisfied: pycparser in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from numba->face_alignment) (0.41.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pooch>=1.0->librosa) (4.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pooch>=1.0->librosa) (23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->face_alignment) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->face_alignment) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->face_alignment) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->face_alignment) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch->face_alignment) (2023.12.2)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from scikit-image->face_alignment) (10.2.0)\n",
      "Collecting imageio>=2.27 (from scikit-image->face_alignment)\n",
      "  Using cached imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->face_alignment)\n",
      "  Using cached tifffile-2024.2.12-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from jinja2->torch->face_alignment) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sympy->torch->face_alignment) (1.3.0)\n",
      "Using cached face_alignment-1.4.1-py2.py3-none-any.whl (30 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "Using cached librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "Using cached Resemblyzer-0.1.4-py3-none-any.whl (15.7 MB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached Cython-3.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Using cached pooch-1.8.1-py3-none-any.whl (62 kB)\n",
      "Using cached soxr-0.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "Using cached imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "Using cached tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: webrtcvad, pydub, typing, tifffile, soxr, lazy-loader, imageio, cython, audioread, soundfile, scikit-image, pyworld, pysptk, pooch, librosa, face_alignment, resemblyzer\n",
      "Successfully installed audioread-3.0.1 cython-3.0.8 face_alignment-1.4.1 imageio-2.34.0 lazy-loader-0.3 librosa-0.10.1 pooch-1.8.1 pydub-0.25.1 pysptk-0.2.2 pyworld-0.3.4 resemblyzer-0.1.4 scikit-image-0.22.0 soundfile-0.12.1 soxr-0.3.7 tifffile-2024.2.12 typing-3.7.4.3 webrtcvad-2.0.10\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python face_alignment scikit-learn pydub soundfile librosa pysptk pyworld resemblyzer tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf942a75-6771-467f-8b29-2673fbc274ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T00:01:39.722916Z",
     "iopub.status.busy": "2024-02-29T00:01:39.722465Z",
     "iopub.status.idle": "2024-02-29T00:01:41.074748Z",
     "shell.execute_reply": "2024-02-29T00:01:41.073701Z",
     "shell.execute_reply.started": "2024-02-29T00:01:39.722882Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'MakeItTalk' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/yzhou359/MakeItTalk\n",
    "# ! export PYTHONPATH=/content/MakeItTalk:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3d2c8-6468-49da-bd5a-bc7ee96b480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir examples/dump\n",
    "! mkdir examples/ckpt\n",
    "! pip install gdown\n",
    "! gdown -O examples/ckpt/ckpt_autovc.pth https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
    "!gdown -O examples/ckpt/ckpt_content_branch.pth https://drive.google.com/uc?id=1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
    "!gdown -O examples/ckpt/ckpt_speaker_branch.pth https://drive.google.com/uc?id=1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
    "!gdown -O examples/ckpt/ckpt_116_i2i_comb.pth https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
    "!gdown -O examples/dump/emb.pickle https://drive.google.com/uc?id=18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
